[
     {
          "algorithm": "A novel reproduction function with simulated binary crossover, adaptive mutation, and generation-wise elitism.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function with simulated binary crossover, adaptive mutation, and generation-wise elitism.}\n    \"\"\"\n    import numpy as np\n    \n    # Parameters\n    eta_c = 20  # Crossover distribution index\n    eta_m = 20  # Mutation distribution index\n    mut_prob = 1.0 / N_P  # Mutation probability per gene\n    elite_factor = 0.1  # Proportion of elite individuals\n    elite_size = int(elite_factor * POP_SIZE)\n\n    # Simulated binary crossover function\n    def simulated_binary_crossover(p1, p2):\n        offspring1, offspring2 = np.copy(p1), np.copy(p2)\n        for i in range(N_P):\n            if np.random.rand() <= 0.5:\n                if abs(p1[i] - p2[i]) > 1e-14:  # Prevent division by zero\n                    y1 = min(p1[i], p2[i])\n                    y2 = max(p1[i], p2[i])\n                    rand = np.random.rand()\n                    beta = 1.0 + (2.0 * (y1 - xlb[i]) / (y2 - y1))\n                    alpha = 2.0 - beta**-(eta_c + 1)\n                    beta_q = 0\n                    if rand <= (1.0 / alpha):\n                        beta_q = (rand * alpha)**(1.0 / (eta_c + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta_c + 1))\n                    c1 = 0.5 * ((y1 + y2) - beta_q * (y2 - y1))\n\n                    beta = 1.0 + (2.0 * (xub[i] - y2) / (y2 - y1))\n                    alpha = 2.0 - beta**-(eta_c + 1)\n                    if rand <= (1.0 / alpha):\n                        beta_q = (rand * alpha)**(1.0 / (eta_c + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta_c + 1))\n                    c2 = 0.5 * ((y1 + y2) + beta_q * (y2 - y1))\n\n                    c1 = np.clip(c1, xlb[i], xub[i])\n                    c2 = np.clip(c2, xlb[i], xub[i])\n\n                    if np.random.rand() <= 0.5:\n                        offspring1[i] = c2\n                        offspring2[i] = c1\n                    else:\n                        offspring1[i] = c1\n                        offspring2[i] = c2\n\n        return offspring1, offspring2\n\n    # Adaptive mutation function\n    def adaptive_mutation(individual):\n        mutant = np.copy(individual)\n        for i in range(N_P):\n            if np.random.rand() < mut_prob:\n                delta = 0\n                rand = np.random.rand()\n                if rand < 0.5:\n                    delta = (2.0 * rand)**(1.0 / (1.0 + eta_m)) - 1.0\n                else:\n                    delta = 1.0 - (2.0 * (1.0 - rand))**(1.0 / (1.0 + eta_m))\n                mutant[i] += delta * (xub[i] - xlb[i])\n                mutant[i] = np.clip(mutant[i], xlb[i], xub[i])\n        return mutant\n\n    # Generation-wise elitism function\n    def elitism(individuals, rankings, elite_size):\n        elite_indices = np.argpartition(rankings, elite_size)[:elite_size]\n        return individuals[elite_indices]\n\n    # Main reproduction function\n    def next_population(pops):\n        individuals = pops['individuals']\n        rankings = pops['rankings']\n        new_individuals = []\n        elite_individuals = elitism(individuals, rankings, elite_size)\n        while len(new_individuals) < POP_SIZE - elite_size:\n            parents_indices = np.random.choice(POP_SIZE, 2, replace=False)\n            p1, p2 = individuals[parents_indices[0]], individuals[parents_indices[1]]\n            offspring1, offspring2 = simulated_binary_crossover(p1, p2)\n            offspring1 = adaptive_mutation(offspring1)\n            offspring2 = adaptive_mutation(offspring2)\n            new_individuals.append(offspring1)\n            if len(new_individuals) < POP_SIZE - elite_size:\n                new_individuals.append(offspring2)\n        new_individuals.extend(elite_individuals)\n        return np.array(new_individuals)\n\n    # Generate the next population\n    new_pops = next_population(pops)\n\n    return new_pops",
          "objective": 0.66578,
          "other_inf": null
     },
     {
          "algorithm": "This novel algorithm uses a simulated annealing inspired selection mechanism with polynomial mutation \n    and single-point crossover to balance exploration and exploitation in generating the next population.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {This novel algorithm uses a simulated annealing inspired selection mechanism with polynomial mutation \n    and single-point crossover to balance exploration and exploitation in generating the next population.}\n    \"\"\"\n    import numpy as np\n    \n    def polynomial_mutation(individual, eta=20):\n        # Polynomial mutation\n        for i in range(N_P):\n            if np.random.rand() < 1.0 / N_P:\n                delta = np.random.rand()\n                if delta < 0.5:\n                    delta_q = (2.0 * delta)**(1.0 / (eta + 1)) - 1.0\n                else:\n                    delta_q = 1.0 - (2.0 * (1.0 - delta))**(1.0 / (eta + 1))\n                individual[i] += delta_q * (xub[i] - xlb[i])\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n    \n    def single_point_crossover(parent1, parent2):\n        # Single-point crossover\n        if np.random.rand() < 0.9:  # Crossover probability\n            point = np.random.randint(1, N_P)\n            return np.concatenate((parent1[:point], parent2[point:]))\n        else:\n            return parent1\n    \n    def simulated_annealing_selection(individual, best_individual, temperature):\n        # Simulated annealing inspired selection\n        cost_diff = np.linalg.norm(individual - best_individual)\n        if cost_diff < 0 or np.random.rand() < np.exp(-cost_diff / temperature):\n            return individual\n        else:\n            return best_individual\n    \n    def generate_new_population(pops):\n        new_pops = []\n        best_individual = pops['individuals'][0]  # Assuming the first individual is the best\n        temperature = max_gen / (current_gen + 1)  # Decreasing temperature\n        \n        for _ in range(POP_SIZE):\n            parent1_idx, parent2_idx = np.random.choice(POP_SIZE, 2, replace=False)\n            parent1 = pops['individuals'][parent1_idx]\n            parent2 = pops['individuals'][parent2_idx]\n            \n            child = single_point_crossover(parent1, parent2)\n            child = polynomial_mutation(child)\n            child = simulated_annealing_selection(child, best_individual, temperature)\n            \n            new_pops.append(child)\n        \n        return np.array(new_pops)\n    \n    new_pops = generate_new_population(pops)\n    return new_pops",
          "objective": 0.33992,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that combines simulated binary crossover (SBX) and Gaussian mutation with a dynamic crowding distance-based selection mechanism.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that combines simulated binary crossover (SBX) and Gaussian mutation with a dynamic crowding distance-based selection mechanism.}\n    \"\"\"\n    import numpy as np\n    \n    # SBX Crossover function\n    def simulated_binary_crossover(p1, p2, eta_c=30):\n        child1, child2 = np.copy(p1), np.copy(p2)\n        for i in range(N_P):\n            if np.random.rand() <= 0.9:  # Crossover probability\n                if abs(p1[i] - p2[i]) > 1e-14:\n                    x1 = min(p1[i], p2[i])\n                    x2 = max(p1[i], p2[i])\n                    xl = xlb[i]\n                    xu = xub[i]\n                    rand = np.random.rand()\n                    beta = 1.0 + (2.0 * (x1 - xl) / (x2 - x1))\n                    alpha = 2.0 - beta**-(eta_c + 1)\n                    if rand <= 1.0 / alpha:\n                        beta_q = (rand * alpha)**(1.0 / (eta_c + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta_c + 1))\n                    c1 = 0.5 * ((x1 + x2) - beta_q * (x2 - x1))\n\n                    beta = 1.0 + (2.0 * (xu - x2) / (x2 - x1))\n                    alpha = 2.0 - beta**-(eta_c + 1)\n                    if rand <= 1.0 / alpha:\n                        beta_q = (rand * alpha)**(1.0 / (eta_c + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta_c + 1))\n                    c2 = 0.5 * ((x1 + x2) + beta_q * (x2 - x1))\n\n                    c1 = np.clip(c1, xl, xu)\n                    c2 = np.clip(c2, xl, xu)\n\n                    if np.random.rand() <= 0.5:\n                        child1[i] = c2\n                        child2[i] = c1\n                    else:\n                        child1[i] = c1\n                        child2[i] = c2\n        return child1, child2\n    \n    # Gaussian mutation function\n    def gaussian_mutation(individual, mu=0, sigma=1):\n        mutant = np.copy(individual)\n        for i in range(N_P):\n            if np.random.rand() < 1 / N_P:  # Mutation probability\n                mutant[i] += np.random.normal(mu, sigma)\n                mutant[i] = np.clip(mutant[i], xlb[i], xub[i])\n        return mutant\n    \n    # Crowding distance-based selection function\n    def crowding_distance_selection(population, distances, num_select):\n        selected_indices = []\n        while len(selected_indices) < num_select:\n            max_distance_index = np.argmax(distances)\n            selected_indices.append(max_distance_index)\n            distances[max_distance_index] = -np.inf  # Exclude the selected index from further consideration\n        return population[selected_indices]\n    \n    # Calculate crowding distances (not a full implementation, just a placeholder)\n    def calculate_crowding_distances(rankings):\n        return 1 / (rankings + 2)  # Placeholder for crowding distance calculation\n    \n    # Main reproduction function\n    def next_population(pops):\n        individuals = pops['individuals']\n        rankings = pops['rankings']\n        distances = calculate_crowding_distances(rankings)\n        new_individuals = np.empty_like(individuals)\n        mating_pool = crowding_distance_selection(individuals, distances, POP_SIZE)\n        for i in range(0, POP_SIZE, 2):\n            p1, p2 = mating_pool[np.random.choice(POP_SIZE, 2, replace=False)]\n            c1, c2 = simulated_binary_crossover(p1, p2)\n            new_individuals[i] = gaussian_mutation(c1)\n            if i + 1 < POP_SIZE:\n                new_individuals[i + 1] = gaussian_mutation(c2)\n        return new_individuals\n    \n    new_pops = next_population(pops)\n    return new_pops",
          "objective": 0.00641,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that combines simulated binary crossover (SBX) with polynomial mutation (PM) and a crowding distance-based selection mechanism.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that combines simulated binary crossover (SBX) with polynomial mutation (PM) and a crowding distance-based selection mechanism.}\n    \"\"\"\n    import numpy as np\n    \n    # Simulated Binary Crossover (SBX) function\n    def sbx_crossover(parent1, parent2, eta=30):\n        child1, child2 = np.copy(parent1), np.copy(parent2)\n        for i in range(N_P):\n            if np.random.rand() <= 0.5:\n                if abs(parent1[i] - parent2[i]) > 1e-14:\n                    x1 = min(parent1[i], parent2[i])\n                    x2 = max(parent1[i], parent2[i])\n                    rand = np.random.rand()\n                    beta = 1.0 + (2.0 * (x1 - xlb[i]) / (x2 - x1))\n                    alpha = 2.0 - beta**-(eta + 1)\n                    if rand <= 1.0 / alpha:\n                        beta_q = (rand * alpha)**(1.0 / (eta + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta + 1))\n                    c1 = 0.5 * ((x1 + x2) - beta_q * (x2 - x1))\n                    \n                    beta = 1.0 + (2.0 * (xub[i] - x2) / (x2 - x1))\n                    alpha = 2.0 - beta**-(eta + 1)\n                    if rand <= 1.0 / alpha:\n                        beta_q = (rand * alpha)**(1.0 / (eta + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta + 1))\n                    c2 = 0.5 * ((x1 + x2) + beta_q * (x2 - x1))\n                    \n                    c1 = np.clip(c1, xlb[i], xub[i])\n                    c2 = np.clip(c2, xlb[i], xub[i])\n                    \n                    if np.random.rand() <= 0.5:\n                        child1[i], child2[i] = c1, c2\n                    else:\n                        child1[i], child2[i] = c2, c1\n        return child1, child2\n    \n    # Polynomial Mutation (PM) function\n    def polynomial_mutation(individual, eta_m=20):\n        mutant = np.copy(individual)\n        for i in range(N_P):\n            if np.random.rand() <= 1/N_P:\n                y = individual[i]\n                delta1 = (y - xlb[i]) / (xub[i] - xlb[i])\n                delta2 = (xub[i] - y) / (xub[i] - xlb[i])\n                rand = np.random.rand()\n                mut_pow = 1.0 / (eta_m + 1.0)\n                if rand <= 0.5:\n                    xy = 1.0 - delta1\n                    val = 2.0 * rand + (1.0 - 2.0 * rand) * (xy**(eta_m + 1))\n                    delta_q = val**mut_pow - 1.0\n                else:\n                    xy = 1.0 - delta2\n                    val = 2.0 * (1.0 - rand) + 2.0 * (rand - 0.5) * (xy**(eta_m + 1))\n                    delta_q = 1.0 - val**mut_pow\n                y = y + delta_q * (xub[i] - xlb[i])\n                mutant[i] = np.clip(y, xlb[i], xub[i])\n        return mutant\n\n    # Crowding distance-based selection function\n    def crowding_distance_selection(population, num_select):\n        distances = np.zeros(POP_SIZE)\n        for i in range(N_P):\n            sorted_indices = np.argsort(population[:, i])\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n            for j in range(1, POP_SIZE - 1):\n                distances[sorted_indices[j]] += (population[sorted_indices[j + 1], i] - population[sorted_indices[j - 1], i]) / (xub[i] - xlb[i])\n        selected_indices = np.argsort(-distances)[:num_select]\n        return population[selected_indices]\n\n    # Main reproduction function\n    def next_population(pops):\n        individuals = pops['individuals']\n        new_population = np.empty_like(individuals)\n        for i in range(0, POP_SIZE, 2):\n            parent1, parent2 = individuals[np.random.randint(0, POP_SIZE)], individuals[np.random.randint(0, POP_SIZE)]\n            child1, child2 = sbx_crossover(parent1, parent2)\n            new_population[i] = polynomial_mutation(child1)\n            if i + 1 < POP_SIZE:\n                new_population[i + 1] = polynomial_mutation(child2)\n        selected_population = crowding_distance_selection(new_population, POP_SIZE)\n        return selected_population\n\n    # Generate the next population\n    new_pops = next_population(pops)\n\n    return new_pops",
          "objective": -0.17306,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that incorporates simulated binary crossover (SBX), polynomial mutation, and non-dominated sorting-based selection.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that incorporates simulated binary crossover (SBX), polynomial mutation, and non-dominated sorting-based selection.}\n    \"\"\"\n    import numpy as np\n    \n    # Parameters\n    crossover_probability = 0.9\n    mutation_probability = 1.0 / N_P\n    distribution_index_crossover = 20\n    distribution_index_mutation = 20\n    \n    # Simulated binary crossover (SBX) function\n    def sbx_crossover(parent1, parent2):\n        if np.random.rand() <= crossover_probability:\n            child1, child2 = np.empty_like(parent1), np.empty_like(parent2)\n            for i in range(N_P):\n                if np.random.rand() <= 0.5:\n                    if abs(parent1[i] - parent2[i]) > 1e-14:  # Avoid division by zero\n                        y1 = min(parent1[i], parent2[i])\n                        y2 = max(parent1[i], parent2[i])\n                        rand = np.random.rand()\n                        beta = 1.0 + (2.0 * (y1 - xlb[i]) / (y2 - y1))\n                        alpha = 2.0 - beta**-(distribution_index_crossover + 1)\n                        betaq = (rand <= (1.0 / alpha)) * (alpha * rand)**(1.0 / (distribution_index_crossover + 1)) + \\\n                                (rand > (1.0 / alpha)) * (1.0 / (2.0 - alpha * rand))**(1.0 / (distribution_index_crossover + 1))\n                        child1[i] = 0.5 * ((1 + betaq) * y1 + (1 - betaq) * y2)\n                        beta = 1.0 + (2.0 * (xub[i] - y2) / (y2 - y1))\n                        alpha = 2.0 - beta**-(distribution_index_crossover + 1)\n                        betaq = (rand <= (1.0 / alpha)) * (alpha * rand)**(1.0 / (distribution_index_crossover + 1)) + \\\n                                (rand > (1.0 / alpha)) * (1.0 / (2.0 - alpha * rand))**(1.0 / (distribution_index_crossover + 1))\n                        child2[i] = 0.5 * ((1 - betaq) * y1 + (1 + betaq) * y2)\n                    else:\n                        child1[i] = parent1[i]\n                        child2[i] = parent2[i]\n                else:\n                    child1[i] = parent1[i]\n                    child2[i] = parent2[i]\n            return child1, child2\n        else:\n            return parent1, parent2\n    \n    # Polynomial mutation function\n    def polynomial_mutation(individual):\n        for i in range(N_P):\n            if np.random.rand() <= mutation_probability:\n                delta = min((individual[i] - xlb[i]) / (xub[i] - xlb[i]), (xub[i] - individual[i]) / (xub[i] - xlb[i]))\n                mut_pow = 1.0 / (distribution_index_mutation + 1.0)\n                rand = np.random.rand()\n                if rand < 0.5:\n                    xy = 1.0 - delta\n                    val = 2.0 * rand + (1.0 - 2.0 * rand) * (xy**(distribution_index_mutation + 1))\n                    deltaq = val**mut_pow - 1.0\n                else:\n                    xy = 1.0 - delta\n                    val = 2.0 * (1.0 - rand) + 2.0 * (rand - 0.5) * (xy**(distribution_index_mutation + 1))\n                    deltaq = 1.0 - val**mut_pow\n                individual[i] += deltaq * (xub[i] - xlb[i])\n                individual[i] = min(max(individual[i], xlb[i]), xub[i])\n        return individual\n    \n    # Non-dominated sorting-based selection function\n    def non_dominated_selection(individuals, rankings):\n        selected_indices = rankings.argsort()[:POP_SIZE]\n        return individuals[selected_indices]\n    \n    # Main reproduction function\n    def next_population(pops):\n        individuals = pops['individuals']\n        rankings = pops['rankings']\n        new_individuals = np.empty_like(individuals)\n        selected_individuals = non_dominated_selection(individuals, rankings)\n        for i in range(0, POP_SIZE, 2):\n            parent1, parent2 = selected_individuals[i], selected_individuals[i + 1]\n            child1, child2 = sbx_crossover(parent1, parent2)\n            new_individuals[i] = polynomial_mutation(child1)\n            if i + 1 < POP_SIZE:\n                new_individuals[i + 1] = polynomial_mutation(child2)\n        return new_individuals\n    \n    # Generate the next population\n    new_pops = next_population(pops)\n    \n    return new_pops",
          "objective": -0.63934,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        child = np.empty(N_P)\n        crossover_point = np.random.randint(1, N_P-1)\n        child[0:crossover_point] = parent1[0:crossover_point]\n        child[crossover_point:] = parent2[crossover_point:]\n        return child\n\n    def mutate(individual):\n        mutation_rate = 0.1 + (0.5 - 0.1) * current_gen / max_gen  # Adaptive mutation rate\n        for i in range(N_P):\n            if np.random.rand() < mutation_rate:\n                individual[i] = individual[i] + np.random.normal(0, (xub[i] - xlb[i]) * 0.1)\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n\n    def create_child(population):\n        parent1, parent2 = np.random.choice(population.shape[0], 2, replace=False)\n        child = crossover(population[parent1], population[parent2])\n        child = mutate(child)\n        return child\n\n    def select_parents(ranked_individuals, tournament_size=2):\n        selected_indices = np.random.choice(ranked_individuals.shape[0], tournament_size, replace=False)\n        selected_individuals = ranked_individuals[selected_indices]\n        best_individual = selected_individuals[np.argmin(pops['rankings'][selected_indices])]\n        return best_individual\n\n    def generate_new_population(population, ranked_individuals):\n        new_population = np.empty((POP_SIZE, N_P))\n        for i in range(POP_SIZE):\n            parent1 = select_parents(ranked_individuals)\n            parent2 = select_parents(ranked_individuals)\n            new_population[i] = create_child(np.vstack((parent1, parent2)))\n        return new_population\n\n    ranked_individuals = pops['individuals']\n    new_pops = generate_new_population(ranked_individuals, ranked_individuals)\n    return new_pops",
          "objective": -0.80699,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that combines differential evolution with a cooling schedule inspired by simulated annealing for adaptive mutation and crossover.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that combines differential evolution with a cooling schedule inspired by simulated annealing for adaptive mutation and crossover.}\n    \"\"\"\n    import numpy as np\n\n    def differential_evolution_mutation(individuals, F):\n        mutant_population = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            mutant_population[i] = np.clip(mutant, xlb, xub)\n        return mutant_population\n\n    def crossover(parents, mutants, CR):\n        trial_population = np.empty_like(parents)\n        for i in range(POP_SIZE):\n            cross_points = np.random.rand(N_P) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, N_P)] = True\n            trial_population[i] = np.where(cross_points, mutants[i], parents[i])\n        return trial_population\n\n    def next_population(pops, F, CR):\n        mutant_population = differential_evolution_mutation(pops['individuals'], F)\n        trial_population = crossover(pops['individuals'], mutant_population, CR)\n        return trial_population\n\n    F = 0.5 * (1 - (current_gen / max_gen))  # Decreasing mutation factor\n    CR = 0.9 * (1 - (current_gen / max_gen))  # Decreasing crossover rate\n    new_pops = next_population(pops, F, CR)\n    \n    return new_pops",
          "objective": -1.21644,
          "other_inf": null
     },
     {
          "algorithm": "The new algorithm uses a dynamic weighted combination of crossover, mutation, and search trajectory to create the next generation.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {The new algorithm uses a dynamic weighted combination of crossover, mutation, and search trajectory to create the next generation.}\n    \"\"\"\n    import numpy as np\n    \n    def crossover(parent1, parent2, crossover_rate):\n        \"\"\"Perform crossover between two parents to produce two offspring.\"\"\"\n        if np.random.rand() < crossover_rate:\n            crossover_point = np.random.randint(1, N_P)\n            offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n            offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n        else:\n            offspring1, offspring2 = parent1.copy(), parent2.copy()\n        return offspring1, offspring2\n    \n    def mutate(individual, mutation_rate):\n        \"\"\"Mutate an individual by randomly changing one of its genes within the bounds.\"\"\"\n        for i in range(N_P):\n            if np.random.rand() < mutation_rate:\n                mutation_value = np.random.uniform(xlb[i], xub[i])\n                individual[i] = mutation_value\n        return individual\n    \n    def select_parents():\n        \"\"\"Select parents using binary tournament selection.\"\"\"\n        parents = []\n        for _ in range(2):\n            contenders_idx = np.random.choice(range(POP_SIZE), 2, replace=False)\n            contender_ranks = pops['rankings'][contenders_idx]\n            parent_idx = contenders_idx[np.argmin(contender_ranks)]\n            parents.append(pops['individuals'][parent_idx])\n        return parents\n    \n    def trajectory_guided_mutation(individual, trajectory_rate):\n        \"\"\"Mutate an individual using historical search trajectory for guidance.\"\"\"\n        if search_trajectory['individuals'] is not None and np.random.rand() < trajectory_rate:\n            historical_individual = search_trajectory['individuals'][np.random.randint(len(search_trajectory['individuals']))]\n            mutation_index = np.random.randint(N_P)\n            alpha = np.random.uniform(0.5, 1.5)\n            individual[mutation_index] = alpha * historical_individual[mutation_index] + (1 - alpha) * individual[mutation_index]\n        return np.clip(individual, xlb, xub)\n    \n    def create_new_population():\n        \"\"\"Create a new population using crossover, mutation, and trajectory guidance.\"\"\"\n        new_population = []\n        crossover_rate = 0.8\n        mutation_rate = 0.2\n        trajectory_rate = current_gen / max_gen\n        while len(new_population) < POP_SIZE:\n            parent1, parent2 = select_parents()\n            offspring1, offspring2 = crossover(parent1, parent2, crossover_rate)\n            offspring1 = mutate(offspring1, mutation_rate)\n            offspring2 = mutate(offspring2, mutation_rate)\n            offspring1 = trajectory_guided_mutation(offspring1, trajectory_rate)\n            offspring2 = trajectory_guided_mutation(offspring2, trajectory_rate)\n            new_population.extend([offspring1, offspring2])\n        return np.array(new_population[:POP_SIZE])\n    \n    new_pops = create_new_population()\n    return new_pops",
          "objective": -1.3107,
          "other_inf": null
     },
     {
          "algorithm": "A novel algorithm that employs differential evolution with adaptive mutation and crossover rates to maintain diversity and converge towards the Pareto-front.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel algorithm that employs differential evolution with adaptive mutation and crossover rates to maintain diversity and converge towards the Pareto-front.}\n    \"\"\"\n    import numpy as np\n    \n    def adaptive_mutation_rate(gen, max_gen):\n        # Adaptively change the mutation rate from high to low\n        return 0.9 - gen * ((0.9 - 0.1) / max_gen)\n    \n    def adaptive_crossover_rate(gen, max_gen):\n        # Adaptively change the crossover rate from low to high\n        return 0.1 + gen * ((0.9 - 0.1) / max_gen)\n    \n    def differential_mutation(individuals, F):\n        # Mutate individuals using differential evolution strategy\n        mutant_population = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            mutant_population[i] = np.clip(mutant, xlb, xub)\n        return mutant_population\n    \n    def crossover(parents, mutants, CR):\n        # Crossover between parents and mutants to create new individuals\n        offspring_population = np.empty_like(parents)\n        for i in range(POP_SIZE):\n            crossover_points = np.random.rand(N_P) < CR\n            if not np.any(crossover_points):\n                crossover_points[np.random.randint(0, N_P)] = True\n            offspring = np.where(crossover_points, mutants[i], parents[i])\n            offspring_population[i] = offspring\n        return offspring_population\n    \n    # Get current individuals\n    current_individuals = pops['individuals']\n    \n    # Calculate adaptive rates for mutation and crossover\n    F = adaptive_mutation_rate(current_gen, max_gen)\n    CR = adaptive_crossover_rate(current_gen, max_gen)\n    \n    # Perform differential mutation\n    mutant_population = differential_mutation(current_individuals, F)\n    \n    # Perform crossover\n    new_pops = crossover(current_individuals, mutant_population, CR)\n    \n    return new_pops",
          "objective": -1.41363,
          "other_inf": null
     },
     {
          "algorithm": "This new algorithm employs a dynamic weighted combination of crossover, mutation, and historical trajectory with \n    an adaptive mutation rate that decreases over generations to refine the search for the Pareto-front.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {This new algorithm employs a dynamic weighted combination of crossover, mutation, and historical trajectory with \n    an adaptive mutation rate that decreases over generations to refine the search for the Pareto-front.}\n    \"\"\"\n    import numpy as np\n    \n    def crossover(parent1, parent2, cr_rate):\n        if np.random.rand() < cr_rate:\n            crossover_point = np.random.randint(1, N_P)\n            offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n            offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n        else:\n            offspring1, offspring2 = parent1.copy(), parent2.copy()\n        return offspring1, offspring2\n    \n    def mutate(individual, mut_rate):\n        if np.random.rand() < mut_rate:\n            mutation_index = np.random.randint(N_P)\n            mutation_value = np.random.uniform(xlb[mutation_index], xub[mutation_index])\n            individual[mutation_index] = mutation_value\n        return individual\n    \n    def select_parents():\n        tournament_size = 2\n        contenders_idx = np.random.choice(range(POP_SIZE), tournament_size, replace=False)\n        parent_idx = contenders_idx[np.argmin(pops['rankings'][contenders_idx])]\n        return pops['individuals'][parent_idx]\n    \n    def trajectory_guided_mutation(individual):\n        if search_trajectory['individuals'] is not None:\n            historical_individual = search_trajectory['individuals'][np.random.randint(len(search_trajectory['individuals']))]\n            for i in range(N_P):\n                if np.random.rand() < (1 - current_gen / max_gen):\n                    alpha = np.random.uniform(0.5, 1.5)\n                    individual[i] = alpha * historical_individual[i] + (1 - alpha) * individual[i]\n        return np.clip(individual, xlb, xub)\n    \n    def create_new_population():\n        new_population = []\n        mutation_rate = 1 - current_gen / max_gen\n        crossover_rate = 0.9\n        while len(new_population) < POP_SIZE:\n            parent1 = select_parents()\n            parent2 = select_parents()\n            offspring1, offspring2 = crossover(parent1, parent2, crossover_rate)\n            offspring1 = mutate(offspring1, mutation_rate)\n            offspring2 = mutate(offspring2, mutation_rate)\n            new_population.extend([offspring1, offspring2])\n        return np.array(new_population[:POP_SIZE])\n    \n    new_pops = create_new_population()\n    for i in range(POP_SIZE):\n        new_pops[i] = trajectory_guided_mutation(new_pops[i])\n    \n    return new_pops",
          "objective": -1.4647,
          "other_inf": null
     }
]
[
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        child = np.empty(N_P)\n        crossover_point = np.random.randint(1, N_P-1)\n        child[0:crossover_point] = parent1[0:crossover_point]\n        child[crossover_point:] = parent2[crossover_point:]\n        return child\n\n    def mutate(individual):\n        mutation_rate = 0.1 + (0.5 - 0.1) * current_gen / max_gen  # Adaptive mutation rate\n        for i in range(N_P):\n            if np.random.rand() < mutation_rate:\n                individual[i] = individual[i] + np.random.normal(0, (xub[i] - xlb[i]) * 0.1)\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n\n    def create_child(population):\n        parent1, parent2 = np.random.choice(population.shape[0], 2, replace=False)\n        child = crossover(population[parent1], population[parent2])\n        child = mutate(child)\n        return child\n\n    def select_parents(ranked_individuals, tournament_size=2):\n        selected_indices = np.random.choice(ranked_individuals.shape[0], tournament_size, replace=False)\n        selected_individuals = ranked_individuals[selected_indices]\n        best_individual = selected_individuals[np.argmin(pops['rankings'][selected_indices])]\n        return best_individual\n\n    def generate_new_population(population, ranked_individuals):\n        new_population = np.empty((POP_SIZE, N_P))\n        for i in range(POP_SIZE):\n            parent1 = select_parents(ranked_individuals)\n            parent2 = select_parents(ranked_individuals)\n            new_population[i] = create_child(np.vstack((parent1, parent2)))\n        return new_population\n\n    ranked_individuals = pops['individuals']\n    new_pops = generate_new_population(ranked_individuals, ranked_individuals)\n    return new_pops",
          "objective": -0.80699,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that combines differential evolution with a cooling schedule inspired by simulated annealing for adaptive mutation and crossover.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that combines differential evolution with a cooling schedule inspired by simulated annealing for adaptive mutation and crossover.}\n    \"\"\"\n    import numpy as np\n\n    def differential_evolution_mutation(individuals, F):\n        mutant_population = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            mutant_population[i] = np.clip(mutant, xlb, xub)\n        return mutant_population\n\n    def crossover(parents, mutants, CR):\n        trial_population = np.empty_like(parents)\n        for i in range(POP_SIZE):\n            cross_points = np.random.rand(N_P) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, N_P)] = True\n            trial_population[i] = np.where(cross_points, mutants[i], parents[i])\n        return trial_population\n\n    def next_population(pops, F, CR):\n        mutant_population = differential_evolution_mutation(pops['individuals'], F)\n        trial_population = crossover(pops['individuals'], mutant_population, CR)\n        return trial_population\n\n    F = 0.5 * (1 - (current_gen / max_gen))  # Decreasing mutation factor\n    CR = 0.9 * (1 - (current_gen / max_gen))  # Decreasing crossover rate\n    new_pops = next_population(pops, F, CR)\n    \n    return new_pops",
          "objective": -1.21644,
          "other_inf": null
     },
     {
          "algorithm": "A novel algorithm that employs differential evolution with adaptive mutation and crossover rates to maintain diversity and converge towards the Pareto-front.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel algorithm that employs differential evolution with adaptive mutation and crossover rates to maintain diversity and converge towards the Pareto-front.}\n    \"\"\"\n    import numpy as np\n    \n    def adaptive_mutation_rate(gen, max_gen):\n        # Adaptively change the mutation rate from high to low\n        return 0.9 - gen * ((0.9 - 0.1) / max_gen)\n    \n    def adaptive_crossover_rate(gen, max_gen):\n        # Adaptively change the crossover rate from low to high\n        return 0.1 + gen * ((0.9 - 0.1) / max_gen)\n    \n    def differential_mutation(individuals, F):\n        # Mutate individuals using differential evolution strategy\n        mutant_population = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            mutant_population[i] = np.clip(mutant, xlb, xub)\n        return mutant_population\n    \n    def crossover(parents, mutants, CR):\n        # Crossover between parents and mutants to create new individuals\n        offspring_population = np.empty_like(parents)\n        for i in range(POP_SIZE):\n            crossover_points = np.random.rand(N_P) < CR\n            if not np.any(crossover_points):\n                crossover_points[np.random.randint(0, N_P)] = True\n            offspring = np.where(crossover_points, mutants[i], parents[i])\n            offspring_population[i] = offspring\n        return offspring_population\n    \n    # Get current individuals\n    current_individuals = pops['individuals']\n    \n    # Calculate adaptive rates for mutation and crossover\n    F = adaptive_mutation_rate(current_gen, max_gen)\n    CR = adaptive_crossover_rate(current_gen, max_gen)\n    \n    # Perform differential mutation\n    mutant_population = differential_mutation(current_individuals, F)\n    \n    # Perform crossover\n    new_pops = crossover(current_individuals, mutant_population, CR)\n    \n    return new_pops",
          "objective": -1.41363,
          "other_inf": null
     },
     {
          "algorithm": "'individuals': new_pops, 'rankings': np.array([])",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The novel algorithm generates the next population by combining mutation, crossover, and historical search trajectory\n    guidance to explore and exploit the search space while preserving diversity and converging towards the Pareto-front.\n    \"\"\"\n    \n    import numpy as np\n    \n    def crossover(parent1, parent2):\n        \"\"\"Perform crossover between two parents to produce two offspring.\"\"\"\n        crossover_point = np.random.randint(1, N_P)\n        offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n        return offspring1, offspring2\n    \n    def mutate(individual):\n        \"\"\"Mutate an individual by randomly changing one of its genes within the bounds.\"\"\"\n        mutation_index = np.random.randint(N_P)\n        mutation_value = np.random.uniform(xlb[mutation_index], xub[mutation_index])\n        individual[mutation_index] = mutation_value\n        return individual\n    \n    def select_parents(ranked_individuals):\n        \"\"\"Select parents using tournament selection.\"\"\"\n        tournament_size = 2\n        parents = []\n        for _ in range(2):\n            contenders_idx = np.random.choice(range(POP_SIZE), tournament_size, replace=False)\n            contenders = ranked_individuals[contenders_idx]\n            parent_idx = contenders_idx[np.argmin(pops['rankings'][contenders_idx])]\n            parents.append(ranked_individuals[parent_idx])\n        return parents\n    \n    def trajectory_guided_mutation(individual):\n        \"\"\"Mutate an individual using historical search trajectory for guidance.\"\"\"\n        if search_trajectory['individuals'] is not None:\n            historical_individual = search_trajectory['individuals'][np.random.randint(len(search_trajectory['individuals']))]\n            mutation_index = np.random.randint(N_P)\n            alpha = np.random.uniform(0.5, 1.5)\n            individual[mutation_index] = alpha * historical_individual[mutation_index] + (1 - alpha) * individual[mutation_index]\n        return np.clip(individual, xlb, xub)\n    \n    def create_new_population(ranked_individuals):\n        \"\"\"Create a new population using crossover and mutation operations.\"\"\"\n        new_population = []\n        while len(new_population) < POP_SIZE:\n            parent1, parent2 = select_parents(ranked_individuals)\n            offspring1, offspring2 = crossover(parent1, parent2)\n            offspring1 = mutate(offspring1)\n            offspring2 = mutate(offspring2)\n            new_population.extend([offspring1, offspring2])\n        return np.array(new_population[:POP_SIZE])\n    \n    def adaptively_guided_population():\n        \"\"\"Adaptively mutate the population using trajectory guidance and traditional mutation.\"\"\"\n        new_population = create_new_population(pops['individuals'])\n        for i in range(POP_SIZE):\n            if np.random.rand() < (current_gen / max_gen):\n                new_population[i] = trajectory_guided_mutation(new_population[i])\n            else:\n                new_population[i] = mutate(new_population[i])\n        return new_population\n    \n    new_pops = adaptively_guided_population()\n    return new_pops",
          "objective": -1.79249,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The algorithm combines simulated binary crossover (SBX), polynomial mutation, and elitism, with an adaptive strategy that emphasizes exploration in early generations and exploitation in later generations.\n    \"\"\"\n    import numpy as np\n    \n    def sbx_crossover(parent1, parent2, eta, lb, ub):\n        child1, child2 = np.copy(parent1), np.copy(parent2)\n        for i in range(len(parent1)):\n            if np.random.rand() <= 0.5:\n                if abs(parent1[i] - parent2[i]) > 1e-14:\n                    x1 = min(parent1[i], parent2[i])\n                    x2 = max(parent1[i], parent2[i])\n                    rand = np.random.rand()\n                    beta = 1.0 + (2.0 * (x1 - lb[i]) / (x2 - x1))\n                    alpha = 2.0 - beta**-(eta + 1)\n                    if rand <= 1.0 / alpha:\n                        beta_q = (rand * alpha)**(1.0 / (eta + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta + 1))\n                    c1 = 0.5 * ((x1 + x2) - beta_q * (x2 - x1))\n\n                    beta = 1.0 + (2.0 * (ub[i] - x2) / (x2 - x1))\n                    alpha = 2.0 - beta**-(eta + 1)\n                    if rand <= 1.0 / alpha:\n                        beta_q = (rand * alpha)**(1.0 / (eta + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta + 1))\n                    c2 = 0.5 * ((x1 + x2) + beta_q * (x2 - x1))\n\n                    c1 = np.clip(c1, lb[i], ub[i])\n                    c2 = np.clip(c2, lb[i], ub[i])\n\n                    if np.random.rand() <= 0.5:\n                        child1[i] = c2\n                        child2[i] = c1\n                    else:\n                        child1[i] = c1\n                        child2[i] = c2\n        return child1, child2\n    \n    def polynomial_mutation(individual, eta_m, lb, ub):\n        mutant = np.copy(individual)\n        for i in range(len(individual)):\n            if np.random.rand() <= (1.0 / N_P):\n                delta_l = (individual[i] - lb[i]) / (ub[i] - lb[i])\n                delta_u = (ub[i] - individual[i]) / (ub[i] - lb[i])\n                rand = np.random.rand()\n                mut_pow = 1.0 / (eta_m + 1.0)\n                if rand < 0.5:\n                    xy = 1.0 - delta_l\n                    val = 2.0 * rand + (1.0 - 2.0 * rand) * (xy**(eta_m + 1))\n                    delta_q = val**mut_pow - 1.0\n                else:\n                    xy = 1.0 - delta_u\n                    val = 2.0 * (1.0 - rand) + 2.0 * (rand - 0.5) * (xy**(eta_m + 1))\n                    delta_q = 1.0 - val**mut_pow\n                mutant[i] = np.clip(individual[i] + delta_q * (ub[i] - lb[i]), lb[i], ub[i])\n        return mutant\n    \n    def select_parents(population):\n        idx = np.random.choice(len(population), 2, replace=False)\n        return population[idx[0]], population[idx[1]]\n    \n    eta_c = 2.0  # Crossover distribution index\n    eta_m = 20.0  # Mutation distribution index\n    prob_crossover = 0.9  # Crossover probability\n    prob_mutation = 1.0 / N_P  # Mutation probability per variable\n    \n    current_population = pops['individuals']\n    new_pops = np.empty_like(current_population)\n    \n    for i in range(0, POP_SIZE, 2):\n        parent1, parent2 = select_parents(current_population)\n        if np.random.rand() < prob_crossover:\n            child1, child2 = sbx_crossover(parent1, parent2, eta_c, xlb, xub)\n        else:\n            child1, child2 = parent1, parent2\n        \n        child1 = polynomial_mutation(child1, eta_m, xlb, xub)\n        child2 = polynomial_mutation(child2, eta_m, xlb, xub)\n        \n        new_pops[i] = child1\n        if i+1 < POP_SIZE:\n            new_pops[i+1] = child2\n    \n    return new_pops",
          "objective": -8.04341,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    This algorithm introduces a differential evolution inspired reproduction function with a blend of\n    adaptive mutation, crossover, and a crowding distance based selection mechanism to maintain diversity.\n    \"\"\"\n    import numpy as np\n\n    def differential_mutation(individuals, F=0.8):\n        idxs = np.random.choice(len(individuals), 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + F * (b - c), xlb, xub)\n        return mutant\n\n    def binomial_crossover(target, donor, CR=0.5):\n        cross_points = np.random.rand(N_P) < CR\n        offspring = np.where(cross_points, donor, target)\n        return offspring\n\n    def crowding_distance_sorting(pops):\n        individuals = pops['individuals']\n        rankings = pops['rankings']\n        distances = np.zeros(POP_SIZE)\n        for i in range(N_P):\n            sorted_indices = np.argsort(individuals[:, i])\n            sorted_individuals = individuals[sorted_indices]\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n            for j in range(1, POP_SIZE - 1):\n                distances[sorted_indices[j]] += (sorted_individuals[j + 1, i] - sorted_individuals[j - 1, i])\n        return np.argsort(-distances)\n\n    def select_individual_by_rank_and_distance(pops):\n        distances_order = crowding_distance_sorting(pops)\n        return pops['individuals'][distances_order[0]]\n\n    def generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen):\n        new_pops = []\n        for i in range(POP_SIZE):\n            target = pops['individuals'][i]\n            mutant = differential_mutation(pops['individuals'])\n            offspring = binomial_crossover(target, mutant)\n            new_pops.append(offspring)\n        new_pops = np.array(new_pops)\n        for i in range(POP_SIZE):\n            if np.random.rand() < (current_gen / max_gen):\n                new_pops[i] = select_individual_by_rank_and_distance(pops)\n        return new_pops\n\n    new_pops = generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen)\n    return new_pops",
          "objective": -8.49432,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    This algorithm introduces a differential evolution inspired mutation, a blend crossover mechanism,\n    and a fitness-based adaptive mutation rate to generate the next population.\n    \"\"\"\n    import numpy as np\n\n    def differential_mutation(individuals, F):\n        idxs = np.random.choice(len(individuals), 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + F * (b - c), xlb, xub)\n        return mutant\n\n    def blend_crossover(parent1, parent2, alpha=0.5):\n        return np.clip(parent1 + alpha * (parent2 - parent1), xlb, xub)\n\n    def fitness_based_mutation_rate(rankings, current_gen, max_gen):\n        return (1 - (rankings / rankings.max())) * (1 - (current_gen / max_gen))\n\n    def generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub):\n        new_pops = []\n        F = 0.8  # Differential evolution mutation factor\n        while len(new_pops) < POP_SIZE:\n            for i in range(len(pops['individuals'])):\n                parent1 = pops['individuals'][i]\n                mutant = differential_mutation(pops['individuals'], F)\n                child = blend_crossover(parent1, mutant)\n                mutation_rate = fitness_based_mutation_rate(pops['rankings'][i], current_gen, max_gen)\n                if np.random.rand() < mutation_rate:\n                    child = differential_mutation(pops['individuals'], F)\n                new_pops.append(child)\n                if len(new_pops) >= POP_SIZE:\n                    break\n        return np.array(new_pops)\n\n    new_pops = generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub)\n    return new_pops",
          "objective": -9.58651,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that combines local search with crossover and a dynamic mutation rate influenced by the generation index.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that combines local search with crossover and a dynamic mutation rate influenced by the generation index.}\n    \"\"\"\n    import numpy as np\n\n    # Dynamic mutation rate based on the generation index\n    mutation_rate = 0.1 + (0.9 * (current_gen / max_gen))\n\n    # Local search function\n    def local_search(individuals):\n        new_individuals = np.copy(individuals)\n        for i in range(POP_SIZE):\n            for j in range(N_P):\n                if np.random.rand() < mutation_rate:\n                    local_perturbation = np.random.uniform(-1, 1) * (xub[j] - xlb[j]) * 0.1\n                    new_individuals[i, j] += local_perturbation\n                    new_individuals[i, j] = np.clip(new_individuals[i, j], xlb[j], xub[j])\n        return new_individuals\n\n    # Crossover function\n    def crossover(individuals):\n        new_individuals = np.copy(individuals)\n        for i in range(0, POP_SIZE, 2):\n            if i + 1 < POP_SIZE:\n                cross_point = np.random.randint(1, N_P)\n                new_individuals[i, :cross_point], new_individuals[i + 1, :cross_point] = \\\n                    new_individuals[i + 1, :cross_point], new_individuals[i, :cross_point]\n        return new_individuals\n\n    # Main reproduction function\n    def next_population(pops):\n        individuals = pops['individuals']\n        individuals = local_search(individuals)\n        individuals = crossover(individuals)\n        return individuals\n\n    # Generate the next population\n    new_pops = next_population(pops)\n\n    return new_pops",
          "objective": -13.81194,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that combines local search with a crossover strategy inspired by genetic algorithms, emphasizing exploitation near the Pareto front and exploration in less crowded areas.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that combines local search with a crossover strategy inspired by genetic algorithms, emphasizing exploitation near the Pareto front and exploration in less crowded areas.}\n    \"\"\"\n    import numpy as np\n\n    def local_search(individual, xlb, xub, step_size=0.1):\n        perturbation = np.random.uniform(-step_size, step_size, size=individual.shape)\n        return np.clip(individual + perturbation, xlb, xub)\n    \n    def genetic_crossover(parent1, parent2):\n        alpha = np.random.rand(N_P)\n        return np.clip(alpha * parent1 + (1 - alpha) * parent2, xlb, xub)\n    \n    def select_parents(ranking):\n        probabilities = (1 / (ranking + 1)) / np.sum(1 / (ranking + 1))\n        parents_indices = np.random.choice(POP_SIZE, size=2, p=probabilities, replace=False)\n        return pops['individuals'][parents_indices[0]], pops['individuals'][parents_indices[1]]\n    \n    def next_population(pops):\n        new_individuals = np.empty_like(pops['individuals'])\n        for i in range(POP_SIZE):\n            if np.random.rand() < (current_gen / max_gen):\n                # Exploitation: Local search around the best individuals\n                new_individuals[i] = local_search(pops['individuals'][i], xlb, xub)\n            else:\n                # Exploration: Crossover between two parents selected based on their rankings\n                parent1, parent2 = select_parents(pops['rankings'])\n                new_individuals[i] = genetic_crossover(parent1, parent2)\n        return new_individuals\n\n    new_pops = next_population(pops)\n    return new_pops",
          "objective": -18.79871,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that employs a blend of quantum-inspired operators and simulated annealing to balance exploration and exploitation.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that employs a blend of quantum-inspired operators and simulated annealing to balance exploration and exploitation.}\n    \"\"\"\n    import numpy as np\n\n    def quantum_inspired_mutation(individuals, theta):\n        new_individuals = np.empty_like(individuals)\n        for i, individual in enumerate(individuals):\n            r = np.random.uniform(-1, 1, size=N_P)\n            new_individuals[i] = individual + theta * np.sin(np.pi * r)\n            new_individuals[i] = np.clip(new_individuals[i], xlb, xub)\n        return new_individuals\n\n    def simulated_annealing(individuals, rankings, temperature):\n        new_individuals = np.copy(individuals)\n        for i in range(POP_SIZE):\n            for j in range(N_P):\n                perturbation = np.random.uniform(-1, 1) * (xub[j] - xlb[j]) * temperature\n                candidate = np.copy(individuals[i])\n                candidate[j] += perturbation\n                candidate[j] = np.clip(candidate[j], xlb[j], xub[j])\n                if np.random.rand() < np.exp((rankings[i] - rankings[np.random.randint(POP_SIZE)]) / temperature):\n                    new_individuals[i] = candidate\n        return new_individuals\n\n    def next_population(pops):\n        temperature = np.exp(-10 * (current_gen / max_gen))\n        theta = 0.1 * (1 - (current_gen / max_gen))\n        new_individuals = quantum_inspired_mutation(pops['individuals'], theta)\n        new_individuals = simulated_annealing(new_individuals, pops['rankings'], temperature)\n        return new_individuals\n\n    new_pops = next_population(pops)\n    return new_pops",
          "objective": -21.15811,
          "other_inf": null
     }
]
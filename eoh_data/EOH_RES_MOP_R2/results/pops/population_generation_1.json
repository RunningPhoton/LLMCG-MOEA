[
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        child = np.empty(N_P)\n        crossover_point = np.random.randint(1, N_P-1)\n        child[0:crossover_point] = parent1[0:crossover_point]\n        child[crossover_point:] = parent2[crossover_point:]\n        return child\n\n    def mutate(individual):\n        mutation_rate = 0.1 + (0.5 - 0.1) * current_gen / max_gen  # Adaptive mutation rate\n        for i in range(N_P):\n            if np.random.rand() < mutation_rate:\n                individual[i] = individual[i] + np.random.normal(0, (xub[i] - xlb[i]) * 0.1)\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n\n    def create_child(population):\n        parent1, parent2 = np.random.choice(population.shape[0], 2, replace=False)\n        child = crossover(population[parent1], population[parent2])\n        child = mutate(child)\n        return child\n\n    def select_parents(ranked_individuals, tournament_size=2):\n        selected_indices = np.random.choice(ranked_individuals.shape[0], tournament_size, replace=False)\n        selected_individuals = ranked_individuals[selected_indices]\n        best_individual = selected_individuals[np.argmin(pops['rankings'][selected_indices])]\n        return best_individual\n\n    def generate_new_population(population, ranked_individuals):\n        new_population = np.empty((POP_SIZE, N_P))\n        for i in range(POP_SIZE):\n            parent1 = select_parents(ranked_individuals)\n            parent2 = select_parents(ranked_individuals)\n            new_population[i] = create_child(np.vstack((parent1, parent2)))\n        return new_population\n\n    ranked_individuals = pops['individuals']\n    new_pops = generate_new_population(ranked_individuals, ranked_individuals)\n    return new_pops",
          "objective": -0.80699,
          "other_inf": null
     },
     {
          "algorithm": "'individuals': new_pops, 'rankings': np.array([])",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The novel algorithm generates the next population by combining mutation, crossover, and historical search trajectory\n    guidance to explore and exploit the search space while preserving diversity and converging towards the Pareto-front.\n    \"\"\"\n    \n    import numpy as np\n    \n    def crossover(parent1, parent2):\n        \"\"\"Perform crossover between two parents to produce two offspring.\"\"\"\n        crossover_point = np.random.randint(1, N_P)\n        offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n        return offspring1, offspring2\n    \n    def mutate(individual):\n        \"\"\"Mutate an individual by randomly changing one of its genes within the bounds.\"\"\"\n        mutation_index = np.random.randint(N_P)\n        mutation_value = np.random.uniform(xlb[mutation_index], xub[mutation_index])\n        individual[mutation_index] = mutation_value\n        return individual\n    \n    def select_parents(ranked_individuals):\n        \"\"\"Select parents using tournament selection.\"\"\"\n        tournament_size = 2\n        parents = []\n        for _ in range(2):\n            contenders_idx = np.random.choice(range(POP_SIZE), tournament_size, replace=False)\n            contenders = ranked_individuals[contenders_idx]\n            parent_idx = contenders_idx[np.argmin(pops['rankings'][contenders_idx])]\n            parents.append(ranked_individuals[parent_idx])\n        return parents\n    \n    def trajectory_guided_mutation(individual):\n        \"\"\"Mutate an individual using historical search trajectory for guidance.\"\"\"\n        if search_trajectory['individuals'] is not None:\n            historical_individual = search_trajectory['individuals'][np.random.randint(len(search_trajectory['individuals']))]\n            mutation_index = np.random.randint(N_P)\n            alpha = np.random.uniform(0.5, 1.5)\n            individual[mutation_index] = alpha * historical_individual[mutation_index] + (1 - alpha) * individual[mutation_index]\n        return np.clip(individual, xlb, xub)\n    \n    def create_new_population(ranked_individuals):\n        \"\"\"Create a new population using crossover and mutation operations.\"\"\"\n        new_population = []\n        while len(new_population) < POP_SIZE:\n            parent1, parent2 = select_parents(ranked_individuals)\n            offspring1, offspring2 = crossover(parent1, parent2)\n            offspring1 = mutate(offspring1)\n            offspring2 = mutate(offspring2)\n            new_population.extend([offspring1, offspring2])\n        return np.array(new_population[:POP_SIZE])\n    \n    def adaptively_guided_population():\n        \"\"\"Adaptively mutate the population using trajectory guidance and traditional mutation.\"\"\"\n        new_population = create_new_population(pops['individuals'])\n        for i in range(POP_SIZE):\n            if np.random.rand() < (current_gen / max_gen):\n                new_population[i] = trajectory_guided_mutation(new_population[i])\n            else:\n                new_population[i] = mutate(new_population[i])\n        return new_population\n    \n    new_pops = adaptively_guided_population()\n    return new_pops",
          "objective": -1.79249,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    This algorithm introduces a differential evolution inspired mutation, a blend crossover mechanism,\n    and a fitness-based adaptive mutation rate to generate the next population.\n    \"\"\"\n    import numpy as np\n\n    def differential_mutation(individuals, F):\n        idxs = np.random.choice(len(individuals), 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + F * (b - c), xlb, xub)\n        return mutant\n\n    def blend_crossover(parent1, parent2, alpha=0.5):\n        return np.clip(parent1 + alpha * (parent2 - parent1), xlb, xub)\n\n    def fitness_based_mutation_rate(rankings, current_gen, max_gen):\n        return (1 - (rankings / rankings.max())) * (1 - (current_gen / max_gen))\n\n    def generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub):\n        new_pops = []\n        F = 0.8  # Differential evolution mutation factor\n        while len(new_pops) < POP_SIZE:\n            for i in range(len(pops['individuals'])):\n                parent1 = pops['individuals'][i]\n                mutant = differential_mutation(pops['individuals'], F)\n                child = blend_crossover(parent1, mutant)\n                mutation_rate = fitness_based_mutation_rate(pops['rankings'][i], current_gen, max_gen)\n                if np.random.rand() < mutation_rate:\n                    child = differential_mutation(pops['individuals'], F)\n                new_pops.append(child)\n                if len(new_pops) >= POP_SIZE:\n                    break\n        return np.array(new_pops)\n\n    new_pops = generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub)\n    return new_pops",
          "objective": -9.58651,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The algorithm generates the next population by combining tournament selection, differential evolution, and guided mutation based on historical search trajectory, with an adaptive strategy that varies between exploration and exploitation based on the current generation.\n    \"\"\"\n    import numpy as np\n    \n    def tournament_selection(population, tournament_size):\n        selected_indices = np.random.choice(range(len(population)), tournament_size, replace=False)\n        selected_individuals = population[selected_indices]\n        selected_rankings = pops['rankings'][selected_indices]\n        winner_index = selected_indices[np.argmin(selected_rankings)]\n        return population[winner_index]\n    \n    def differential_evolution(individual, population, F):\n        r1, r2, r3 = np.random.choice(range(len(population)), 3, replace=False)\n        x1, x2, x3 = population[r1], population[r2], population[r3]\n        mutant = np.clip(x1 + F * (x2 - x3), xlb, xub)\n        return mutant\n    \n    def guided_mutation(individual, trajectory, mutation_rate):\n        if trajectory['individuals'] is not None and len(trajectory['individuals']) > 0:\n            historical_best = trajectory['individuals'][np.argmin(trajectory['rankings'])]\n            mutant = individual + mutation_rate * (historical_best - individual)\n            return np.clip(mutant, xlb, xub)\n        else:\n            return individual\n    \n    def crossover(parent, donor, CR):\n        crossover_mask = np.random.rand(N_P) < CR\n        child = np.where(crossover_mask, donor, parent)\n        return child\n    \n    def create_new_individual(current_population, trajectory, gen_ratio):\n        parent = tournament_selection(current_population, tournament_size=2)\n        F = 0.5 * (1 + gen_ratio)  # Differential weight factor\n        CR = 0.5 * (1 - gen_ratio)  # Crossover probability\n        mutation_rate = 0.1 * (1 - gen_ratio)\n        \n        donor = differential_evolution(parent, current_population, F)\n        child = crossover(parent, donor, CR)\n        mutated_child = guided_mutation(child, trajectory, mutation_rate)\n        return mutated_child\n    \n    new_pops = np.empty((POP_SIZE, N_P))\n    current_population = pops['individuals']\n    gen_ratio = current_gen / max_gen  # A ratio to adjust strategies over generations\n    \n    for i in range(POP_SIZE):\n        new_pops[i] = create_new_individual(current_population, search_trajectory, gen_ratio)\n    \n    return new_pops",
          "objective": -21.53157,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that leverages differential evolution and adaptive mutation strategies, guided by the search trajectory to explore the solution space efficiently.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that leverages differential evolution and adaptive mutation strategies, guided by the search trajectory to explore the solution space efficiently.}\n    \"\"\"\n    import numpy as np\n\n    def differential_evolution(individuals):\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        new_individuals = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            cross_points = np.random.rand(N_P) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, N_P)] = True\n            trial = np.where(cross_points, mutant, individuals[i])\n            trial = np.clip(trial, xlb, xub)\n            new_individuals[i] = trial\n        return new_individuals\n\n    def adaptive_mutation(individuals):\n        tau = 1.0 / np.sqrt(2.0 * np.sqrt(N_P))\n        tau_prime = 1.0 / np.sqrt(2.0 * N_P)\n        for i in range(POP_SIZE):\n            if np.random.rand() < tau_prime:\n                individuals[i] += np.random.randn() * (xub - xlb) * tau\n                individuals[i] = np.clip(individuals[i], xlb, xub)\n        return individuals\n\n    def guided_mutation(individuals, trajectory):\n        if trajectory['individuals'] is not None:\n            history_size = trajectory['individuals'].shape[0]\n            for i in range(POP_SIZE):\n                historical_individual = trajectory['individuals'][np.random.randint(history_size)]\n                individuals[i] = (individuals[i] + historical_individual) / 2.0\n                individuals[i] = np.clip(individuals[i], xlb, xub)\n        return individuals\n\n    # Main reproduction function\n    def next_population(pops, search_trajectory):\n        individuals = pops['individuals']\n        individuals = differential_evolution(individuals)\n        individuals = adaptive_mutation(individuals)\n        individuals = guided_mutation(individuals, search_trajectory)\n        return individuals\n\n    # Generate the next population\n    new_pops = next_population(pops, search_trajectory)\n\n    return new_pops",
          "objective": -21.58973,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The algorithm combines differential evolution with a local search heuristic based on the search trajectory,\n    using adaptive mutation and crossover rates that evolve with the generation count.\n    \"\"\"\n\n    import numpy as np\n\n    def differential_evolution(individuals, rankings, cr, f):\n        def mutate(target_idx):\n            idxs = [idx for idx in range(len(individuals)) if idx != target_idx]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + f * (b - c), xlb, xub)\n            return mutant\n\n        def crossover(target, mutant):\n            cross_points = np.random.rand(N_P) < cr\n            trial = np.where(cross_points, mutant, target)\n            return trial\n\n        new_individuals = np.empty_like(individuals)\n        for i, target in enumerate(individuals):\n            mutant = mutate(i)\n            trial = crossover(target, mutant)\n            new_individuals[i] = trial\n        return new_individuals\n\n    def local_search(individuals, trajectory, search_intensity):\n        if trajectory['individuals'] is not None:\n            historical_best = trajectory['individuals'][np.argmin(trajectory['rankings'])]\n            for i, individual in enumerate(individuals):\n                if np.random.rand() < search_intensity:\n                    direction = historical_best - individual\n                    individuals[i] = np.clip(individual + np.random.rand(N_P) * direction, xlb, xub)\n        return individuals\n\n    def adaptive_rates(current_gen, max_gen):\n        cr = 0.5 + 0.5 * (current_gen / max_gen)\n        f = 0.5 * (1 - (current_gen / max_gen))\n        search_intensity = 0.1 + 0.4 * (current_gen / max_gen)\n        return cr, f, search_intensity\n\n    def next_population(pops):\n        cr, f, search_intensity = adaptive_rates(current_gen, max_gen)\n        new_individuals = differential_evolution(pops['individuals'], pops['rankings'], cr, f)\n        new_individuals = local_search(new_individuals, search_trajectory, search_intensity)\n        return new_individuals\n\n    new_pops = next_population(pops)\n    return new_pops",
          "objective": -22.1314,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    A novel multi-objective evolutionary algorithm that uses a combination of elitism, diversity preservation, \n    and adaptive mutation based on search history to generate the next population aiming for the Pareto-front.\n    \"\"\"\n    import numpy as np\n\n    def adaptive_mutation(individual, gen, max_gen, xlb, xub):\n        # Adaptive mutation strength based on generation\n        mutation_strength = (1 - (gen / max_gen)) * (xub - xlb)\n        return individual + np.random.uniform(-mutation_strength, mutation_strength, size=individual.shape)\n    \n    def crossover(parent1, parent2):\n        # Single point crossover\n        cross_point = np.random.randint(1, N_P)\n        child1 = np.concatenate((parent1[:cross_point], parent2[cross_point:]))\n        child2 = np.concatenate((parent2[:cross_point], parent1[cross_point:]))\n        return child1, child2\n\n    def select_parents(pops, POP_SIZE):\n        # Tournament selection\n        tournament_size = 2\n        selected_parents = []\n        for _ in range(POP_SIZE // 2):\n            candidates_idx = np.random.choice(range(POP_SIZE), tournament_size, replace=False)\n            candidates = pops['individuals'][candidates_idx]\n            candidate_ranks = pops['rankings'][candidates_idx]\n            winner_idx = candidates_idx[np.argmin(candidate_ranks)]\n            selected_parents.append(pops['individuals'][winner_idx])\n        return np.array(selected_parents)\n\n    def ensure_bounds(individual, xlb, xub):\n        return np.clip(individual, xlb, xub)\n\n    def generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub):\n        parents = select_parents(pops, POP_SIZE)\n        new_pops = []\n        for i in range(0, POP_SIZE, 2):\n            parent1, parent2 = parents[i % len(parents)], parents[(i + 1) % len(parents)]\n            child1, child2 = crossover(parent1, parent2)\n            child1 = adaptive_mutation(child1, current_gen, max_gen, xlb, xub)\n            child2 = adaptive_mutation(child2, current_gen, max_gen, xlb, xub)\n            child1 = ensure_bounds(child1, xlb, xub)\n            child2 = ensure_bounds(child2, xlb, xub)\n            new_pops.append(child1)\n            new_pops.append(child2)\n        return np.array(new_pops[:POP_SIZE])\n\n    new_pops = generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub)\n    return new_pops",
          "objective": -31.99673,
          "other_inf": null
     },
     {
          "algorithm": "A novel evolutionary reproduction function that emphasizes adaptability by dynamically adjusting the balance between exploration and exploitation based on the generation index, using differential evolution for crossover and an adaptive mutation strategy.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel evolutionary reproduction function that emphasizes adaptability by dynamically adjusting the balance between exploration and exploitation based on the generation index, using differential evolution for crossover and an adaptive mutation strategy.}\n    \"\"\"\n    import numpy as np\n\n    def differential_crossover(target, donor1, donor2, donor3, cr):\n        trial = np.copy(target)\n        j_rand = np.random.randint(N_P)\n        for j in range(N_P):\n            if np.random.rand() < cr or j == j_rand:\n                trial[j] = donor1[j] + 0.5 * (donor2[j] - donor3[j])\n        return trial\n\n    def adaptive_mutation(individual, gen_factor):\n        sigma = np.random.normal(0, (1 - gen_factor) * (xub - xlb))\n        return individual + sigma\n\n    def select_donors(population, current):\n        indices = [idx for idx in range(POP_SIZE) if idx != current]\n        return population[np.random.choice(indices, 3, replace=False)]\n\n    gen_factor = current_gen / max_gen\n    cr = 0.1 + 0.5 * gen_factor  # Crossover rate that adapts over generations\n\n    new_pops = np.empty((POP_SIZE, N_P))\n    for i in range(POP_SIZE):\n        target = pops['individuals'][i]\n        donor1, donor2, donor3 = select_donors(pops['individuals'], i)\n        trial = differential_crossover(target, donor1, donor2, donor3, cr)\n        mutant = adaptive_mutation(trial, gen_factor)\n        new_pops[i] = np.clip(mutant, xlb, xub)\n\n    return new_pops",
          "objective": -32.92974,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def differential_evolution_crossover(target, donor1, donor2, donor3, cr):\n        trial = np.copy(target)\n        j_rand = np.random.randint(N_P)\n        for j in range(N_P):\n            if np.random.rand() < cr or j == j_rand:\n                trial[j] = donor1[j] + 0.5 * (donor2[j] - donor3[j])\n        return trial\n\n    def mutation(individual, sigma):\n        return np.clip(individual + np.random.normal(0, sigma, size=(N_P,)), xlb, xub)\n\n    def select_donors(population, target_index, num_donors=3):\n        donor_indices = np.random.choice([i for i in range(POP_SIZE) if i != target_index], num_donors, replace=False)\n        return population[donor_indices]\n\n    def create_new_individual(i):\n        target = pops['individuals'][i]\n        donors = select_donors(pops['individuals'], i)\n        cr = 0.5  # Crossover probability\n        trial = differential_evolution_crossover(target, *donors, cr)\n        sigma = (1 - (current_gen / max_gen)) * (xub - xlb) / 2  # Mutation strength\n        trial = mutation(trial, sigma)\n        return trial\n\n    new_pops = np.array([create_new_individual(i) for i in range(POP_SIZE)])\n    return new_pops",
          "objective": -34.77587,
          "other_inf": null
     },
     {
          "algorithm": "A novel algorithm that utilizes a blend of swarm intelligence and adaptive gradient-based updates to efficiently explore the search space and exploit promising areas for Pareto-front approximation.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel algorithm that utilizes a blend of swarm intelligence and adaptive gradient-based updates to efficiently explore the search space and exploit promising areas for Pareto-front approximation.}\n    \"\"\"\n    import numpy as np\n    \n    def get_inertia_weight(gen, max_gen):\n        # Linearly decreasing inertia weight\n        return 0.9 - gen * ((0.9 - 0.4) / max_gen)\n    \n    def get_personal_best(pops):\n        # Get the personal best positions of individuals\n        return pops['individuals']\n    \n    def get_global_best(pops):\n        # Get the global best position among individuals\n        return pops['individuals'][0]\n\n    def update_velocity(velocity, personal_best, global_best, inertia_weight, cognitive_component, social_component):\n        # Update the velocity based on personal best, global best, and inertia\n        r1, r2 = np.random.rand(N_P), np.random.rand(N_P)\n        cognitive_velocity = cognitive_component * r1 * (personal_best - pops['individuals'])\n        social_velocity = social_component * r2 * (global_best - pops['individuals'])\n        new_velocity = inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n    \n    def update_positions(positions, velocity, xlb, xub):\n        # Update the positions based on velocity and ensure they are within bounds\n        new_positions = positions + velocity\n        new_positions = np.clip(new_positions, xlb, xub)\n        return new_positions\n    \n    # Initialize velocity\n    velocity = np.zeros((POP_SIZE, N_P))\n    inertia_weight = get_inertia_weight(current_gen, max_gen)\n    cognitive_component = 2.0\n    social_component = 2.0\n    \n    # Get personal best and global best positions\n    personal_best = get_personal_best(pops)\n    global_best = get_global_best(pops)\n    \n    # Update velocity and positions\n    velocity = update_velocity(velocity, personal_best, global_best, inertia_weight, cognitive_component, social_component)\n    new_pops = update_positions(pops['individuals'], velocity, xlb, xub)\n    \n    return new_pops",
          "objective": -42.76068,
          "other_inf": null
     }
]
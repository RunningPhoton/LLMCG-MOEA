[
     {
          "algorithm": "A novel reproduction function with simulated binary crossover, adaptive mutation, and generation-wise elitism.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function with simulated binary crossover, adaptive mutation, and generation-wise elitism.}\n    \"\"\"\n    import numpy as np\n    \n    # Parameters\n    eta_c = 20  # Crossover distribution index\n    eta_m = 20  # Mutation distribution index\n    mut_prob = 1.0 / N_P  # Mutation probability per gene\n    elite_factor = 0.1  # Proportion of elite individuals\n    elite_size = int(elite_factor * POP_SIZE)\n\n    # Simulated binary crossover function\n    def simulated_binary_crossover(p1, p2):\n        offspring1, offspring2 = np.copy(p1), np.copy(p2)\n        for i in range(N_P):\n            if np.random.rand() <= 0.5:\n                if abs(p1[i] - p2[i]) > 1e-14:  # Prevent division by zero\n                    y1 = min(p1[i], p2[i])\n                    y2 = max(p1[i], p2[i])\n                    rand = np.random.rand()\n                    beta = 1.0 + (2.0 * (y1 - xlb[i]) / (y2 - y1))\n                    alpha = 2.0 - beta**-(eta_c + 1)\n                    beta_q = 0\n                    if rand <= (1.0 / alpha):\n                        beta_q = (rand * alpha)**(1.0 / (eta_c + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta_c + 1))\n                    c1 = 0.5 * ((y1 + y2) - beta_q * (y2 - y1))\n\n                    beta = 1.0 + (2.0 * (xub[i] - y2) / (y2 - y1))\n                    alpha = 2.0 - beta**-(eta_c + 1)\n                    if rand <= (1.0 / alpha):\n                        beta_q = (rand * alpha)**(1.0 / (eta_c + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta_c + 1))\n                    c2 = 0.5 * ((y1 + y2) + beta_q * (y2 - y1))\n\n                    c1 = np.clip(c1, xlb[i], xub[i])\n                    c2 = np.clip(c2, xlb[i], xub[i])\n\n                    if np.random.rand() <= 0.5:\n                        offspring1[i] = c2\n                        offspring2[i] = c1\n                    else:\n                        offspring1[i] = c1\n                        offspring2[i] = c2\n\n        return offspring1, offspring2\n\n    # Adaptive mutation function\n    def adaptive_mutation(individual):\n        mutant = np.copy(individual)\n        for i in range(N_P):\n            if np.random.rand() < mut_prob:\n                delta = 0\n                rand = np.random.rand()\n                if rand < 0.5:\n                    delta = (2.0 * rand)**(1.0 / (1.0 + eta_m)) - 1.0\n                else:\n                    delta = 1.0 - (2.0 * (1.0 - rand))**(1.0 / (1.0 + eta_m))\n                mutant[i] += delta * (xub[i] - xlb[i])\n                mutant[i] = np.clip(mutant[i], xlb[i], xub[i])\n        return mutant\n\n    # Generation-wise elitism function\n    def elitism(individuals, rankings, elite_size):\n        elite_indices = np.argpartition(rankings, elite_size)[:elite_size]\n        return individuals[elite_indices]\n\n    # Main reproduction function\n    def next_population(pops):\n        individuals = pops['individuals']\n        rankings = pops['rankings']\n        new_individuals = []\n        elite_individuals = elitism(individuals, rankings, elite_size)\n        while len(new_individuals) < POP_SIZE - elite_size:\n            parents_indices = np.random.choice(POP_SIZE, 2, replace=False)\n            p1, p2 = individuals[parents_indices[0]], individuals[parents_indices[1]]\n            offspring1, offspring2 = simulated_binary_crossover(p1, p2)\n            offspring1 = adaptive_mutation(offspring1)\n            offspring2 = adaptive_mutation(offspring2)\n            new_individuals.append(offspring1)\n            if len(new_individuals) < POP_SIZE - elite_size:\n                new_individuals.append(offspring2)\n        new_individuals.extend(elite_individuals)\n        return np.array(new_individuals)\n\n    # Generate the next population\n    new_pops = next_population(pops)\n\n    return new_pops",
          "objective": 0.66578,
          "other_inf": null
     },
     {
          "algorithm": "This novel algorithm uses a simulated annealing inspired selection mechanism with polynomial mutation \n    and single-point crossover to balance exploration and exploitation in generating the next population.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {This novel algorithm uses a simulated annealing inspired selection mechanism with polynomial mutation \n    and single-point crossover to balance exploration and exploitation in generating the next population.}\n    \"\"\"\n    import numpy as np\n    \n    def polynomial_mutation(individual, eta=20):\n        # Polynomial mutation\n        for i in range(N_P):\n            if np.random.rand() < 1.0 / N_P:\n                delta = np.random.rand()\n                if delta < 0.5:\n                    delta_q = (2.0 * delta)**(1.0 / (eta + 1)) - 1.0\n                else:\n                    delta_q = 1.0 - (2.0 * (1.0 - delta))**(1.0 / (eta + 1))\n                individual[i] += delta_q * (xub[i] - xlb[i])\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n    \n    def single_point_crossover(parent1, parent2):\n        # Single-point crossover\n        if np.random.rand() < 0.9:  # Crossover probability\n            point = np.random.randint(1, N_P)\n            return np.concatenate((parent1[:point], parent2[point:]))\n        else:\n            return parent1\n    \n    def simulated_annealing_selection(individual, best_individual, temperature):\n        # Simulated annealing inspired selection\n        cost_diff = np.linalg.norm(individual - best_individual)\n        if cost_diff < 0 or np.random.rand() < np.exp(-cost_diff / temperature):\n            return individual\n        else:\n            return best_individual\n    \n    def generate_new_population(pops):\n        new_pops = []\n        best_individual = pops['individuals'][0]  # Assuming the first individual is the best\n        temperature = max_gen / (current_gen + 1)  # Decreasing temperature\n        \n        for _ in range(POP_SIZE):\n            parent1_idx, parent2_idx = np.random.choice(POP_SIZE, 2, replace=False)\n            parent1 = pops['individuals'][parent1_idx]\n            parent2 = pops['individuals'][parent2_idx]\n            \n            child = single_point_crossover(parent1, parent2)\n            child = polynomial_mutation(child)\n            child = simulated_annealing_selection(child, best_individual, temperature)\n            \n            new_pops.append(child)\n        \n        return np.array(new_pops)\n    \n    new_pops = generate_new_population(pops)\n    return new_pops",
          "objective": 0.33992,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        child = np.empty(N_P)\n        crossover_point = np.random.randint(1, N_P-1)\n        child[0:crossover_point] = parent1[0:crossover_point]\n        child[crossover_point:] = parent2[crossover_point:]\n        return child\n\n    def mutate(individual):\n        mutation_rate = 0.1 + (0.5 - 0.1) * current_gen / max_gen  # Adaptive mutation rate\n        for i in range(N_P):\n            if np.random.rand() < mutation_rate:\n                individual[i] = individual[i] + np.random.normal(0, (xub[i] - xlb[i]) * 0.1)\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n\n    def create_child(population):\n        parent1, parent2 = np.random.choice(population.shape[0], 2, replace=False)\n        child = crossover(population[parent1], population[parent2])\n        child = mutate(child)\n        return child\n\n    def select_parents(ranked_individuals, tournament_size=2):\n        selected_indices = np.random.choice(ranked_individuals.shape[0], tournament_size, replace=False)\n        selected_individuals = ranked_individuals[selected_indices]\n        best_individual = selected_individuals[np.argmin(pops['rankings'][selected_indices])]\n        return best_individual\n\n    def generate_new_population(population, ranked_individuals):\n        new_population = np.empty((POP_SIZE, N_P))\n        for i in range(POP_SIZE):\n            parent1 = select_parents(ranked_individuals)\n            parent2 = select_parents(ranked_individuals)\n            new_population[i] = create_child(np.vstack((parent1, parent2)))\n        return new_population\n\n    ranked_individuals = pops['individuals']\n    new_pops = generate_new_population(ranked_individuals, ranked_individuals)\n    return new_pops",
          "objective": -0.80699,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that combines differential evolution with a cooling schedule inspired by simulated annealing for adaptive mutation and crossover.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that combines differential evolution with a cooling schedule inspired by simulated annealing for adaptive mutation and crossover.}\n    \"\"\"\n    import numpy as np\n\n    def differential_evolution_mutation(individuals, F):\n        mutant_population = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            mutant_population[i] = np.clip(mutant, xlb, xub)\n        return mutant_population\n\n    def crossover(parents, mutants, CR):\n        trial_population = np.empty_like(parents)\n        for i in range(POP_SIZE):\n            cross_points = np.random.rand(N_P) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, N_P)] = True\n            trial_population[i] = np.where(cross_points, mutants[i], parents[i])\n        return trial_population\n\n    def next_population(pops, F, CR):\n        mutant_population = differential_evolution_mutation(pops['individuals'], F)\n        trial_population = crossover(pops['individuals'], mutant_population, CR)\n        return trial_population\n\n    F = 0.5 * (1 - (current_gen / max_gen))  # Decreasing mutation factor\n    CR = 0.9 * (1 - (current_gen / max_gen))  # Decreasing crossover rate\n    new_pops = next_population(pops, F, CR)\n    \n    return new_pops",
          "objective": -1.21644,
          "other_inf": null
     },
     {
          "algorithm": "A novel algorithm that employs differential evolution with adaptive mutation and crossover rates to maintain diversity and converge towards the Pareto-front.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel algorithm that employs differential evolution with adaptive mutation and crossover rates to maintain diversity and converge towards the Pareto-front.}\n    \"\"\"\n    import numpy as np\n    \n    def adaptive_mutation_rate(gen, max_gen):\n        # Adaptively change the mutation rate from high to low\n        return 0.9 - gen * ((0.9 - 0.1) / max_gen)\n    \n    def adaptive_crossover_rate(gen, max_gen):\n        # Adaptively change the crossover rate from low to high\n        return 0.1 + gen * ((0.9 - 0.1) / max_gen)\n    \n    def differential_mutation(individuals, F):\n        # Mutate individuals using differential evolution strategy\n        mutant_population = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            mutant_population[i] = np.clip(mutant, xlb, xub)\n        return mutant_population\n    \n    def crossover(parents, mutants, CR):\n        # Crossover between parents and mutants to create new individuals\n        offspring_population = np.empty_like(parents)\n        for i in range(POP_SIZE):\n            crossover_points = np.random.rand(N_P) < CR\n            if not np.any(crossover_points):\n                crossover_points[np.random.randint(0, N_P)] = True\n            offspring = np.where(crossover_points, mutants[i], parents[i])\n            offspring_population[i] = offspring\n        return offspring_population\n    \n    # Get current individuals\n    current_individuals = pops['individuals']\n    \n    # Calculate adaptive rates for mutation and crossover\n    F = adaptive_mutation_rate(current_gen, max_gen)\n    CR = adaptive_crossover_rate(current_gen, max_gen)\n    \n    # Perform differential mutation\n    mutant_population = differential_mutation(current_individuals, F)\n    \n    # Perform crossover\n    new_pops = crossover(current_individuals, mutant_population, CR)\n    \n    return new_pops",
          "objective": -1.41363,
          "other_inf": null
     },
     {
          "algorithm": "'individuals': new_pops, 'rankings': np.array([])",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The novel algorithm generates the next population by combining mutation, crossover, and historical search trajectory\n    guidance to explore and exploit the search space while preserving diversity and converging towards the Pareto-front.\n    \"\"\"\n    \n    import numpy as np\n    \n    def crossover(parent1, parent2):\n        \"\"\"Perform crossover between two parents to produce two offspring.\"\"\"\n        crossover_point = np.random.randint(1, N_P)\n        offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n        return offspring1, offspring2\n    \n    def mutate(individual):\n        \"\"\"Mutate an individual by randomly changing one of its genes within the bounds.\"\"\"\n        mutation_index = np.random.randint(N_P)\n        mutation_value = np.random.uniform(xlb[mutation_index], xub[mutation_index])\n        individual[mutation_index] = mutation_value\n        return individual\n    \n    def select_parents(ranked_individuals):\n        \"\"\"Select parents using tournament selection.\"\"\"\n        tournament_size = 2\n        parents = []\n        for _ in range(2):\n            contenders_idx = np.random.choice(range(POP_SIZE), tournament_size, replace=False)\n            contenders = ranked_individuals[contenders_idx]\n            parent_idx = contenders_idx[np.argmin(pops['rankings'][contenders_idx])]\n            parents.append(ranked_individuals[parent_idx])\n        return parents\n    \n    def trajectory_guided_mutation(individual):\n        \"\"\"Mutate an individual using historical search trajectory for guidance.\"\"\"\n        if search_trajectory['individuals'] is not None:\n            historical_individual = search_trajectory['individuals'][np.random.randint(len(search_trajectory['individuals']))]\n            mutation_index = np.random.randint(N_P)\n            alpha = np.random.uniform(0.5, 1.5)\n            individual[mutation_index] = alpha * historical_individual[mutation_index] + (1 - alpha) * individual[mutation_index]\n        return np.clip(individual, xlb, xub)\n    \n    def create_new_population(ranked_individuals):\n        \"\"\"Create a new population using crossover and mutation operations.\"\"\"\n        new_population = []\n        while len(new_population) < POP_SIZE:\n            parent1, parent2 = select_parents(ranked_individuals)\n            offspring1, offspring2 = crossover(parent1, parent2)\n            offspring1 = mutate(offspring1)\n            offspring2 = mutate(offspring2)\n            new_population.extend([offspring1, offspring2])\n        return np.array(new_population[:POP_SIZE])\n    \n    def adaptively_guided_population():\n        \"\"\"Adaptively mutate the population using trajectory guidance and traditional mutation.\"\"\"\n        new_population = create_new_population(pops['individuals'])\n        for i in range(POP_SIZE):\n            if np.random.rand() < (current_gen / max_gen):\n                new_population[i] = trajectory_guided_mutation(new_population[i])\n            else:\n                new_population[i] = mutate(new_population[i])\n        return new_population\n    \n    new_pops = adaptively_guided_population()\n    return new_pops",
          "objective": -1.79249,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm introduces a dynamic adaptive strategy that adjusts crossover and mutation rates based on the current generation, promoting exploration in early stages and exploitation in later stages, and incorporates a tournament selection mechanism for parent selection.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {This algorithm introduces a dynamic adaptive strategy that adjusts crossover and mutation rates based on the current generation, promoting exploration in early stages and exploitation in later stages, and incorporates a tournament selection mechanism for parent selection.}\n    \"\"\"\n    import numpy as np\n\n    def tournament_selection(population, k=2):\n        best = None\n        for _ in range(k):\n            ind = np.random.randint(0, len(population))\n            if (best is None) or (pops['rankings'][ind] < pops['rankings'][best]):\n                best = ind\n        return population[best]\n\n    def dynamic_parameters(current_gen, max_gen):\n        # Dynamically adjust parameters based on the generation\n        crossover_rate = 0.9 - 0.5 * (current_gen / max_gen)\n        mutation_rate = 0.1 + 0.4 * (current_gen / max_gen)\n        return crossover_rate, mutation_rate\n\n    def uniform_crossover(parent1, parent2):\n        child1, child2 = np.copy(parent1), np.copy(parent2)\n        for i in range(len(parent1)):\n            if np.random.rand() <= 0.5:\n                child1[i], child2[i] = child2[i], child1[i]\n        return child1, child2\n\n    def random_mutation(individual, mutation_rate, lb, ub):\n        mutant = np.copy(individual)\n        for i in range(len(individual)):\n            if np.random.rand() <= mutation_rate:\n                mutant[i] = np.random.uniform(lb[i], ub[i])\n        return mutant\n\n    # Get dynamic parameters\n    crossover_rate, mutation_rate = dynamic_parameters(current_gen, max_gen)\n\n    current_population = pops['individuals']\n    new_pops = np.empty_like(current_population)\n\n    for i in range(0, POP_SIZE, 2):\n        parent1 = tournament_selection(current_population)\n        parent2 = tournament_selection(current_population)\n        if np.random.rand() < crossover_rate:\n            child1, child2 = uniform_crossover(parent1, parent2)\n        else:\n            child1, child2 = parent1, parent2\n\n        child1 = random_mutation(child1, mutation_rate, xlb, xub)\n        child2 = random_mutation(child2, mutation_rate, xlb, xub)\n\n        new_pops[i] = child1\n        if i+1 < POP_SIZE:\n            new_pops[i+1] = child2\n\n    return new_pops",
          "objective": -2.00623,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The new algorithm uses a tournament selection mechanism with local search inspired mutation and a simulated binary crossover (SBX) to generate the next population.\n    \"\"\"\n    import numpy as np\n\n    def tournament_selection(individuals, rankings, tournament_size=2):\n        selected = []\n        for _ in range(tournament_size):\n            i = np.random.randint(len(individuals))\n            selected.append((rankings[i], individuals[i]))\n        selected.sort(key=lambda x: x[0])\n        return selected[0][1]\n\n    def local_search_mutation(individual, mutation_strength=0.1):\n        return np.clip(individual + np.random.normal(0, mutation_strength, size=N_P), xlb, xub)\n\n    def simulated_binary_crossover(parent1, parent2, eta=30):\n        u = np.random.rand(N_P)\n        beta = np.empty(N_P)\n        beta[u <= 0.5] = (2 * u[u <= 0.5]) ** (1 / (eta + 1))\n        beta[u > 0.5] = (2 - 2 * u[u > 0.5]) ** (-1 / (eta + 1))\n        child1 = 0.5 * ((1 + beta) * parent1 + (1 - beta) * parent2)\n        child2 = 0.5 * ((1 - beta) * parent1 + (1 + beta) * parent2)\n        return np.clip(np.where(np.random.rand(N_P) < 0.5, child1, child2), xlb, xub)\n\n    new_pops = np.empty((POP_SIZE, N_P))\n    for i in range(POP_SIZE):\n        parent1 = tournament_selection(pops['individuals'], pops['rankings'])\n        parent2 = tournament_selection(pops['individuals'], pops['rankings'])\n        child = simulated_binary_crossover(parent1, parent2)\n        if np.random.rand() < (1 - current_gen / max_gen):\n            child = local_search_mutation(child)\n        new_pops[i] = child\n\n    return new_pops",
          "objective": -2.70478,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that employs tournament selection, adaptive differential evolution, and elitism.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that employs tournament selection, adaptive differential evolution, and elitism.}\n    \"\"\"\n    import numpy as np\n\n    # Adaptive parameters\n    F = 0.5  # Differential weight\n    CR = 0.9  # Crossover probability\n    elite_size = int(0.1 * POP_SIZE)  # Number of elites to keep\n\n    # Tournament selection function\n    def tournament_selection(individuals, rankings, tournament_size=2):\n        selected = []\n        for _ in range(POP_SIZE):\n            participants = np.random.choice(POP_SIZE, tournament_size, replace=False)\n            winner = participants[np.argmin(rankings[participants])]\n            selected.append(individuals[winner])\n        return np.array(selected)\n\n    # Differential evolution function\n    def differential_evolution(individuals):\n        new_individuals = np.copy(individuals)\n        for i in range(POP_SIZE):\n            a, b, c = np.random.choice(POP_SIZE, 3, replace=False)\n            mutant = individuals[a] + F * (individuals[b] - individuals[c])\n            cross_points = np.random.rand(N_P) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, N_P)] = True\n            new_individuals[i, cross_points] = mutant[cross_points]\n            new_individuals[i] = np.clip(new_individuals[i], xlb, xub)\n        return new_individuals\n\n    # Elitism function\n    def elitism(individuals, rankings, elite_size):\n        elite_indices = np.argpartition(rankings, elite_size)[:elite_size]\n        return individuals[elite_indices]\n\n    # Main reproduction function\n    def next_population(pops):\n        individuals = pops['individuals']\n        rankings = pops['rankings']\n        selected_individuals = tournament_selection(individuals, rankings)\n        evolved_individuals = differential_evolution(selected_individuals)\n        elite_individuals = elitism(individuals, rankings, elite_size)\n        evolved_individuals[-elite_size:] = elite_individuals\n        return evolved_individuals\n\n    # Generate the next population\n    new_pops = next_population(pops)\n\n    return new_pops",
          "objective": -2.74095,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The algorithm integrates differential evolution with polynomial mutation and elitism, adjusting mutation rates based on generation count.\n    \"\"\"\n    import numpy as np\n    \n    def differential_evolution(parents, F, CR, lb, ub):\n        target, a, b, c = parents\n        mutant = np.copy(target)\n        j_rand = np.random.randint(len(target))\n        for j in range(len(target)):\n            if np.random.rand() < CR or j == j_rand:\n                mutant[j] = a[j] + F * (b[j] - c[j])\n                mutant[j] = np.clip(mutant[j], lb[j], ub[j])\n        return mutant\n    \n    def polynomial_mutation(individual, eta_m, lb, ub):\n        mutant = np.copy(individual)\n        for i in range(len(individual)):\n            if np.random.rand() <= (1.0 / N_P):\n                delta_l = (individual[i] - lb[i]) / (ub[i] - lb[i])\n                delta_u = (ub[i] - individual[i]) / (ub[i] - lb[i])\n                rand = np.random.rand()\n                mut_pow = 1.0 / (eta_m + 1.0)\n                if rand < 0.5:\n                    xy = 1.0 - delta_l\n                    val = 2.0 * rand + (1.0 - 2.0 * rand) * (xy**(eta_m + 1))\n                    delta_q = val**mut_pow - 1.0\n                else:\n                    xy = 1.0 - delta_u\n                    val = 2.0 * (1.0 - rand) + 2.0 * (rand - 0.5) * (xy**(eta_m + 1))\n                    delta_q = 1.0 - val**mut_pow\n                mutant[i] = np.clip(individual[i] + delta_q * (ub[i] - lb[i]), lb[i], ub[i])\n        return mutant\n    \n    def select_parents(population, size):\n        indices = np.random.choice(len(population), size, replace=False)\n        return population[indices]\n    \n    F = 0.5  # Differential evolution scaling factor\n    CR = 0.9  # Crossover probability for differential evolution\n    eta_m = 20.0  # Mutation distribution index\n    mutation_rate = 1.0 - current_gen / max_gen  # Adaptive mutation rate\n    \n    current_population = pops['individuals']\n    new_pops = np.empty_like(current_population)\n    \n    for i in range(POP_SIZE):\n        parents = select_parents(current_population, 4)\n        mutant = differential_evolution(parents, F, CR, xlb, xub)\n        if np.random.rand() < mutation_rate:\n            mutant = polynomial_mutation(mutant, eta_m, xlb, xub)\n        new_pops[i] = mutant\n    \n    # Elitism: replace the worst individual with the best one from the previous generation if it's better\n    best_individual = current_population[0]  # Assuming the population is sorted by fitness\n    worst_new_individual_idx = np.argmax(np.array([np.sum(np.square(individual - xlb) + np.square(individual - xub)) for individual in new_pops]))\n    worst_new_individual = new_pops[worst_new_individual_idx]\n    if np.sum(np.square(best_individual - xlb) + np.square(best_individual - xub)) < np.sum(np.square(worst_new_individual - xlb) + np.square(worst_new_individual - xub)):\n        new_pops[worst_new_individual_idx] = best_individual\n    \n    return new_pops",
          "objective": -3.39724,
          "other_inf": null
     }
]
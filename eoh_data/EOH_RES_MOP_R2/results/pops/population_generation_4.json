[
     {
          "algorithm": "This novel algorithm uses a simulated annealing inspired selection mechanism with polynomial mutation \n    and single-point crossover to balance exploration and exploitation in generating the next population.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {This novel algorithm uses a simulated annealing inspired selection mechanism with polynomial mutation \n    and single-point crossover to balance exploration and exploitation in generating the next population.}\n    \"\"\"\n    import numpy as np\n    \n    def polynomial_mutation(individual, eta=20):\n        # Polynomial mutation\n        for i in range(N_P):\n            if np.random.rand() < 1.0 / N_P:\n                delta = np.random.rand()\n                if delta < 0.5:\n                    delta_q = (2.0 * delta)**(1.0 / (eta + 1)) - 1.0\n                else:\n                    delta_q = 1.0 - (2.0 * (1.0 - delta))**(1.0 / (eta + 1))\n                individual[i] += delta_q * (xub[i] - xlb[i])\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n    \n    def single_point_crossover(parent1, parent2):\n        # Single-point crossover\n        if np.random.rand() < 0.9:  # Crossover probability\n            point = np.random.randint(1, N_P)\n            return np.concatenate((parent1[:point], parent2[point:]))\n        else:\n            return parent1\n    \n    def simulated_annealing_selection(individual, best_individual, temperature):\n        # Simulated annealing inspired selection\n        cost_diff = np.linalg.norm(individual - best_individual)\n        if cost_diff < 0 or np.random.rand() < np.exp(-cost_diff / temperature):\n            return individual\n        else:\n            return best_individual\n    \n    def generate_new_population(pops):\n        new_pops = []\n        best_individual = pops['individuals'][0]  # Assuming the first individual is the best\n        temperature = max_gen / (current_gen + 1)  # Decreasing temperature\n        \n        for _ in range(POP_SIZE):\n            parent1_idx, parent2_idx = np.random.choice(POP_SIZE, 2, replace=False)\n            parent1 = pops['individuals'][parent1_idx]\n            parent2 = pops['individuals'][parent2_idx]\n            \n            child = single_point_crossover(parent1, parent2)\n            child = polynomial_mutation(child)\n            child = simulated_annealing_selection(child, best_individual, temperature)\n            \n            new_pops.append(child)\n        \n        return np.array(new_pops)\n    \n    new_pops = generate_new_population(pops)\n    return new_pops",
          "objective": 0.33992,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        child = np.empty(N_P)\n        crossover_point = np.random.randint(1, N_P-1)\n        child[0:crossover_point] = parent1[0:crossover_point]\n        child[crossover_point:] = parent2[crossover_point:]\n        return child\n\n    def mutate(individual):\n        mutation_rate = 0.1 + (0.5 - 0.1) * current_gen / max_gen  # Adaptive mutation rate\n        for i in range(N_P):\n            if np.random.rand() < mutation_rate:\n                individual[i] = individual[i] + np.random.normal(0, (xub[i] - xlb[i]) * 0.1)\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n\n    def create_child(population):\n        parent1, parent2 = np.random.choice(population.shape[0], 2, replace=False)\n        child = crossover(population[parent1], population[parent2])\n        child = mutate(child)\n        return child\n\n    def select_parents(ranked_individuals, tournament_size=2):\n        selected_indices = np.random.choice(ranked_individuals.shape[0], tournament_size, replace=False)\n        selected_individuals = ranked_individuals[selected_indices]\n        best_individual = selected_individuals[np.argmin(pops['rankings'][selected_indices])]\n        return best_individual\n\n    def generate_new_population(population, ranked_individuals):\n        new_population = np.empty((POP_SIZE, N_P))\n        for i in range(POP_SIZE):\n            parent1 = select_parents(ranked_individuals)\n            parent2 = select_parents(ranked_individuals)\n            new_population[i] = create_child(np.vstack((parent1, parent2)))\n        return new_population\n\n    ranked_individuals = pops['individuals']\n    new_pops = generate_new_population(ranked_individuals, ranked_individuals)\n    return new_pops",
          "objective": -0.80699,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that combines differential evolution with a cooling schedule inspired by simulated annealing for adaptive mutation and crossover.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that combines differential evolution with a cooling schedule inspired by simulated annealing for adaptive mutation and crossover.}\n    \"\"\"\n    import numpy as np\n\n    def differential_evolution_mutation(individuals, F):\n        mutant_population = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            mutant_population[i] = np.clip(mutant, xlb, xub)\n        return mutant_population\n\n    def crossover(parents, mutants, CR):\n        trial_population = np.empty_like(parents)\n        for i in range(POP_SIZE):\n            cross_points = np.random.rand(N_P) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, N_P)] = True\n            trial_population[i] = np.where(cross_points, mutants[i], parents[i])\n        return trial_population\n\n    def next_population(pops, F, CR):\n        mutant_population = differential_evolution_mutation(pops['individuals'], F)\n        trial_population = crossover(pops['individuals'], mutant_population, CR)\n        return trial_population\n\n    F = 0.5 * (1 - (current_gen / max_gen))  # Decreasing mutation factor\n    CR = 0.9 * (1 - (current_gen / max_gen))  # Decreasing crossover rate\n    new_pops = next_population(pops, F, CR)\n    \n    return new_pops",
          "objective": -1.21644,
          "other_inf": null
     },
     {
          "algorithm": "A novel algorithm that employs differential evolution with adaptive mutation and crossover rates to maintain diversity and converge towards the Pareto-front.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel algorithm that employs differential evolution with adaptive mutation and crossover rates to maintain diversity and converge towards the Pareto-front.}\n    \"\"\"\n    import numpy as np\n    \n    def adaptive_mutation_rate(gen, max_gen):\n        # Adaptively change the mutation rate from high to low\n        return 0.9 - gen * ((0.9 - 0.1) / max_gen)\n    \n    def adaptive_crossover_rate(gen, max_gen):\n        # Adaptively change the crossover rate from low to high\n        return 0.1 + gen * ((0.9 - 0.1) / max_gen)\n    \n    def differential_mutation(individuals, F):\n        # Mutate individuals using differential evolution strategy\n        mutant_population = np.empty_like(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + F * (b - c)\n            mutant_population[i] = np.clip(mutant, xlb, xub)\n        return mutant_population\n    \n    def crossover(parents, mutants, CR):\n        # Crossover between parents and mutants to create new individuals\n        offspring_population = np.empty_like(parents)\n        for i in range(POP_SIZE):\n            crossover_points = np.random.rand(N_P) < CR\n            if not np.any(crossover_points):\n                crossover_points[np.random.randint(0, N_P)] = True\n            offspring = np.where(crossover_points, mutants[i], parents[i])\n            offspring_population[i] = offspring\n        return offspring_population\n    \n    # Get current individuals\n    current_individuals = pops['individuals']\n    \n    # Calculate adaptive rates for mutation and crossover\n    F = adaptive_mutation_rate(current_gen, max_gen)\n    CR = adaptive_crossover_rate(current_gen, max_gen)\n    \n    # Perform differential mutation\n    mutant_population = differential_mutation(current_individuals, F)\n    \n    # Perform crossover\n    new_pops = crossover(current_individuals, mutant_population, CR)\n    \n    return new_pops",
          "objective": -1.41363,
          "other_inf": null
     },
     {
          "algorithm": "'individuals': new_pops, 'rankings': np.array([])",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The novel algorithm generates the next population by combining mutation, crossover, and historical search trajectory\n    guidance to explore and exploit the search space while preserving diversity and converging towards the Pareto-front.\n    \"\"\"\n    \n    import numpy as np\n    \n    def crossover(parent1, parent2):\n        \"\"\"Perform crossover between two parents to produce two offspring.\"\"\"\n        crossover_point = np.random.randint(1, N_P)\n        offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n        return offspring1, offspring2\n    \n    def mutate(individual):\n        \"\"\"Mutate an individual by randomly changing one of its genes within the bounds.\"\"\"\n        mutation_index = np.random.randint(N_P)\n        mutation_value = np.random.uniform(xlb[mutation_index], xub[mutation_index])\n        individual[mutation_index] = mutation_value\n        return individual\n    \n    def select_parents(ranked_individuals):\n        \"\"\"Select parents using tournament selection.\"\"\"\n        tournament_size = 2\n        parents = []\n        for _ in range(2):\n            contenders_idx = np.random.choice(range(POP_SIZE), tournament_size, replace=False)\n            contenders = ranked_individuals[contenders_idx]\n            parent_idx = contenders_idx[np.argmin(pops['rankings'][contenders_idx])]\n            parents.append(ranked_individuals[parent_idx])\n        return parents\n    \n    def trajectory_guided_mutation(individual):\n        \"\"\"Mutate an individual using historical search trajectory for guidance.\"\"\"\n        if search_trajectory['individuals'] is not None:\n            historical_individual = search_trajectory['individuals'][np.random.randint(len(search_trajectory['individuals']))]\n            mutation_index = np.random.randint(N_P)\n            alpha = np.random.uniform(0.5, 1.5)\n            individual[mutation_index] = alpha * historical_individual[mutation_index] + (1 - alpha) * individual[mutation_index]\n        return np.clip(individual, xlb, xub)\n    \n    def create_new_population(ranked_individuals):\n        \"\"\"Create a new population using crossover and mutation operations.\"\"\"\n        new_population = []\n        while len(new_population) < POP_SIZE:\n            parent1, parent2 = select_parents(ranked_individuals)\n            offspring1, offspring2 = crossover(parent1, parent2)\n            offspring1 = mutate(offspring1)\n            offspring2 = mutate(offspring2)\n            new_population.extend([offspring1, offspring2])\n        return np.array(new_population[:POP_SIZE])\n    \n    def adaptively_guided_population():\n        \"\"\"Adaptively mutate the population using trajectory guidance and traditional mutation.\"\"\"\n        new_population = create_new_population(pops['individuals'])\n        for i in range(POP_SIZE):\n            if np.random.rand() < (current_gen / max_gen):\n                new_population[i] = trajectory_guided_mutation(new_population[i])\n            else:\n                new_population[i] = mutate(new_population[i])\n        return new_population\n    \n    new_pops = adaptively_guided_population()\n    return new_pops",
          "objective": -1.79249,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that employs tournament selection, adaptive differential evolution, and elitism.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that employs tournament selection, adaptive differential evolution, and elitism.}\n    \"\"\"\n    import numpy as np\n\n    # Adaptive parameters\n    F = 0.5  # Differential weight\n    CR = 0.9  # Crossover probability\n    elite_size = int(0.1 * POP_SIZE)  # Number of elites to keep\n\n    # Tournament selection function\n    def tournament_selection(individuals, rankings, tournament_size=2):\n        selected = []\n        for _ in range(POP_SIZE):\n            participants = np.random.choice(POP_SIZE, tournament_size, replace=False)\n            winner = participants[np.argmin(rankings[participants])]\n            selected.append(individuals[winner])\n        return np.array(selected)\n\n    # Differential evolution function\n    def differential_evolution(individuals):\n        new_individuals = np.copy(individuals)\n        for i in range(POP_SIZE):\n            a, b, c = np.random.choice(POP_SIZE, 3, replace=False)\n            mutant = individuals[a] + F * (individuals[b] - individuals[c])\n            cross_points = np.random.rand(N_P) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, N_P)] = True\n            new_individuals[i, cross_points] = mutant[cross_points]\n            new_individuals[i] = np.clip(new_individuals[i], xlb, xub)\n        return new_individuals\n\n    # Elitism function\n    def elitism(individuals, rankings, elite_size):\n        elite_indices = np.argpartition(rankings, elite_size)[:elite_size]\n        return individuals[elite_indices]\n\n    # Main reproduction function\n    def next_population(pops):\n        individuals = pops['individuals']\n        rankings = pops['rankings']\n        selected_individuals = tournament_selection(individuals, rankings)\n        evolved_individuals = differential_evolution(selected_individuals)\n        elite_individuals = elitism(individuals, rankings, elite_size)\n        evolved_individuals[-elite_size:] = elite_individuals\n        return evolved_individuals\n\n    # Generate the next population\n    new_pops = next_population(pops)\n\n    return new_pops",
          "objective": -2.74095,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that integrates differential evolution with a mutation strategy to balance exploration and exploitation throughout the generations.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel reproduction function that integrates differential evolution with a mutation strategy to balance exploration and exploitation throughout the generations.}\n    \"\"\"\n    import numpy as np\n    \n    def differential_mutation(individuals, F=0.8):\n        idxs = np.random.choice(POP_SIZE, 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + F * (b - c), xlb, xub)\n        return mutant\n    \n    def crossover(individual, mutant, CR=0.5):\n        cross_points = np.random.rand(N_P) < CR\n        offspring = np.where(cross_points, mutant, individual)\n        return np.clip(offspring, xlb, xub)\n    \n    def select_individual_by_rank(ranking):\n        probabilities = (1 / (ranking + 1)) / np.sum(1 / (ranking + 1))\n        idx = np.random.choice(POP_SIZE, p=probabilities)\n        return pops['individuals'][idx]\n    \n    def next_population(pops):\n        new_individuals = np.empty_like(pops['individuals'])\n        for i in range(POP_SIZE):\n            if np.random.rand() < 0.5 + (current_gen / max_gen) * 0.5:\n                # Exploitation: Differential mutation based on rank-selected individuals\n                target = select_individual_by_rank(pops['rankings'])\n                mutant = differential_mutation(pops['individuals'])\n                new_individuals[i] = crossover(target, mutant)\n            else:\n                # Exploration: Mutation based on random selection\n                new_individuals[i] = differential_mutation(pops['individuals'])\n        return new_individuals\n\n    new_pops = next_population(pops)\n    return new_pops",
          "objective": -5.60214,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The algorithm combines simulated binary crossover (SBX), polynomial mutation, and elitism, with an adaptive strategy that emphasizes exploration in early generations and exploitation in later generations.\n    \"\"\"\n    import numpy as np\n    \n    def sbx_crossover(parent1, parent2, eta, lb, ub):\n        child1, child2 = np.copy(parent1), np.copy(parent2)\n        for i in range(len(parent1)):\n            if np.random.rand() <= 0.5:\n                if abs(parent1[i] - parent2[i]) > 1e-14:\n                    x1 = min(parent1[i], parent2[i])\n                    x2 = max(parent1[i], parent2[i])\n                    rand = np.random.rand()\n                    beta = 1.0 + (2.0 * (x1 - lb[i]) / (x2 - x1))\n                    alpha = 2.0 - beta**-(eta + 1)\n                    if rand <= 1.0 / alpha:\n                        beta_q = (rand * alpha)**(1.0 / (eta + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta + 1))\n                    c1 = 0.5 * ((x1 + x2) - beta_q * (x2 - x1))\n\n                    beta = 1.0 + (2.0 * (ub[i] - x2) / (x2 - x1))\n                    alpha = 2.0 - beta**-(eta + 1)\n                    if rand <= 1.0 / alpha:\n                        beta_q = (rand * alpha)**(1.0 / (eta + 1))\n                    else:\n                        beta_q = (1.0 / (2.0 - rand * alpha))**(1.0 / (eta + 1))\n                    c2 = 0.5 * ((x1 + x2) + beta_q * (x2 - x1))\n\n                    c1 = np.clip(c1, lb[i], ub[i])\n                    c2 = np.clip(c2, lb[i], ub[i])\n\n                    if np.random.rand() <= 0.5:\n                        child1[i] = c2\n                        child2[i] = c1\n                    else:\n                        child1[i] = c1\n                        child2[i] = c2\n        return child1, child2\n    \n    def polynomial_mutation(individual, eta_m, lb, ub):\n        mutant = np.copy(individual)\n        for i in range(len(individual)):\n            if np.random.rand() <= (1.0 / N_P):\n                delta_l = (individual[i] - lb[i]) / (ub[i] - lb[i])\n                delta_u = (ub[i] - individual[i]) / (ub[i] - lb[i])\n                rand = np.random.rand()\n                mut_pow = 1.0 / (eta_m + 1.0)\n                if rand < 0.5:\n                    xy = 1.0 - delta_l\n                    val = 2.0 * rand + (1.0 - 2.0 * rand) * (xy**(eta_m + 1))\n                    delta_q = val**mut_pow - 1.0\n                else:\n                    xy = 1.0 - delta_u\n                    val = 2.0 * (1.0 - rand) + 2.0 * (rand - 0.5) * (xy**(eta_m + 1))\n                    delta_q = 1.0 - val**mut_pow\n                mutant[i] = np.clip(individual[i] + delta_q * (ub[i] - lb[i]), lb[i], ub[i])\n        return mutant\n    \n    def select_parents(population):\n        idx = np.random.choice(len(population), 2, replace=False)\n        return population[idx[0]], population[idx[1]]\n    \n    eta_c = 2.0  # Crossover distribution index\n    eta_m = 20.0  # Mutation distribution index\n    prob_crossover = 0.9  # Crossover probability\n    prob_mutation = 1.0 / N_P  # Mutation probability per variable\n    \n    current_population = pops['individuals']\n    new_pops = np.empty_like(current_population)\n    \n    for i in range(0, POP_SIZE, 2):\n        parent1, parent2 = select_parents(current_population)\n        if np.random.rand() < prob_crossover:\n            child1, child2 = sbx_crossover(parent1, parent2, eta_c, xlb, xub)\n        else:\n            child1, child2 = parent1, parent2\n        \n        child1 = polynomial_mutation(child1, eta_m, xlb, xub)\n        child2 = polynomial_mutation(child2, eta_m, xlb, xub)\n        \n        new_pops[i] = child1\n        if i+1 < POP_SIZE:\n            new_pops[i+1] = child2\n    \n    return new_pops",
          "objective": -8.04341,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    This algorithm introduces a differential evolution inspired reproduction function with a blend of\n    adaptive mutation, crossover, and a crowding distance based selection mechanism to maintain diversity.\n    \"\"\"\n    import numpy as np\n\n    def differential_mutation(individuals, F=0.8):\n        idxs = np.random.choice(len(individuals), 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + F * (b - c), xlb, xub)\n        return mutant\n\n    def binomial_crossover(target, donor, CR=0.5):\n        cross_points = np.random.rand(N_P) < CR\n        offspring = np.where(cross_points, donor, target)\n        return offspring\n\n    def crowding_distance_sorting(pops):\n        individuals = pops['individuals']\n        rankings = pops['rankings']\n        distances = np.zeros(POP_SIZE)\n        for i in range(N_P):\n            sorted_indices = np.argsort(individuals[:, i])\n            sorted_individuals = individuals[sorted_indices]\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n            for j in range(1, POP_SIZE - 1):\n                distances[sorted_indices[j]] += (sorted_individuals[j + 1, i] - sorted_individuals[j - 1, i])\n        return np.argsort(-distances)\n\n    def select_individual_by_rank_and_distance(pops):\n        distances_order = crowding_distance_sorting(pops)\n        return pops['individuals'][distances_order[0]]\n\n    def generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen):\n        new_pops = []\n        for i in range(POP_SIZE):\n            target = pops['individuals'][i]\n            mutant = differential_mutation(pops['individuals'])\n            offspring = binomial_crossover(target, mutant)\n            new_pops.append(offspring)\n        new_pops = np.array(new_pops)\n        for i in range(POP_SIZE):\n            if np.random.rand() < (current_gen / max_gen):\n                new_pops[i] = select_individual_by_rank_and_distance(pops)\n        return new_pops\n\n    new_pops = generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen)\n    return new_pops",
          "objective": -8.49432,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    This algorithm introduces a differential evolution inspired mutation, a blend crossover mechanism,\n    and a fitness-based adaptive mutation rate to generate the next population.\n    \"\"\"\n    import numpy as np\n\n    def differential_mutation(individuals, F):\n        idxs = np.random.choice(len(individuals), 3, replace=False)\n        a, b, c = individuals[idxs]\n        mutant = np.clip(a + F * (b - c), xlb, xub)\n        return mutant\n\n    def blend_crossover(parent1, parent2, alpha=0.5):\n        return np.clip(parent1 + alpha * (parent2 - parent1), xlb, xub)\n\n    def fitness_based_mutation_rate(rankings, current_gen, max_gen):\n        return (1 - (rankings / rankings.max())) * (1 - (current_gen / max_gen))\n\n    def generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub):\n        new_pops = []\n        F = 0.8  # Differential evolution mutation factor\n        while len(new_pops) < POP_SIZE:\n            for i in range(len(pops['individuals'])):\n                parent1 = pops['individuals'][i]\n                mutant = differential_mutation(pops['individuals'], F)\n                child = blend_crossover(parent1, mutant)\n                mutation_rate = fitness_based_mutation_rate(pops['rankings'][i], current_gen, max_gen)\n                if np.random.rand() < mutation_rate:\n                    child = differential_mutation(pops['individuals'], F)\n                new_pops.append(child)\n                if len(new_pops) >= POP_SIZE:\n                    break\n        return np.array(new_pops)\n\n    new_pops = generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub)\n    return new_pops",
          "objective": -9.58651,
          "other_inf": null
     }
]
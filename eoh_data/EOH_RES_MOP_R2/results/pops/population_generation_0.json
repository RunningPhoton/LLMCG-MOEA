[
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        child = np.empty(N_P)\n        crossover_point = np.random.randint(1, N_P-1)\n        child[0:crossover_point] = parent1[0:crossover_point]\n        child[crossover_point:] = parent2[crossover_point:]\n        return child\n\n    def mutate(individual):\n        mutation_rate = 0.1 + (0.5 - 0.1) * current_gen / max_gen  # Adaptive mutation rate\n        for i in range(N_P):\n            if np.random.rand() < mutation_rate:\n                individual[i] = individual[i] + np.random.normal(0, (xub[i] - xlb[i]) * 0.1)\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n\n    def create_child(population):\n        parent1, parent2 = np.random.choice(population.shape[0], 2, replace=False)\n        child = crossover(population[parent1], population[parent2])\n        child = mutate(child)\n        return child\n\n    def select_parents(ranked_individuals, tournament_size=2):\n        selected_indices = np.random.choice(ranked_individuals.shape[0], tournament_size, replace=False)\n        selected_individuals = ranked_individuals[selected_indices]\n        best_individual = selected_individuals[np.argmin(pops['rankings'][selected_indices])]\n        return best_individual\n\n    def generate_new_population(population, ranked_individuals):\n        new_population = np.empty((POP_SIZE, N_P))\n        for i in range(POP_SIZE):\n            parent1 = select_parents(ranked_individuals)\n            parent2 = select_parents(ranked_individuals)\n            new_population[i] = create_child(np.vstack((parent1, parent2)))\n        return new_population\n\n    ranked_individuals = pops['individuals']\n    new_pops = generate_new_population(ranked_individuals, ranked_individuals)\n    return new_pops",
          "objective": -0.80699,
          "other_inf": null
     },
     {
          "algorithm": "'individuals': new_pops, 'rankings': np.array([])",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The novel algorithm generates the next population by combining mutation, crossover, and historical search trajectory\n    guidance to explore and exploit the search space while preserving diversity and converging towards the Pareto-front.\n    \"\"\"\n    \n    import numpy as np\n    \n    def crossover(parent1, parent2):\n        \"\"\"Perform crossover between two parents to produce two offspring.\"\"\"\n        crossover_point = np.random.randint(1, N_P)\n        offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n        return offspring1, offspring2\n    \n    def mutate(individual):\n        \"\"\"Mutate an individual by randomly changing one of its genes within the bounds.\"\"\"\n        mutation_index = np.random.randint(N_P)\n        mutation_value = np.random.uniform(xlb[mutation_index], xub[mutation_index])\n        individual[mutation_index] = mutation_value\n        return individual\n    \n    def select_parents(ranked_individuals):\n        \"\"\"Select parents using tournament selection.\"\"\"\n        tournament_size = 2\n        parents = []\n        for _ in range(2):\n            contenders_idx = np.random.choice(range(POP_SIZE), tournament_size, replace=False)\n            contenders = ranked_individuals[contenders_idx]\n            parent_idx = contenders_idx[np.argmin(pops['rankings'][contenders_idx])]\n            parents.append(ranked_individuals[parent_idx])\n        return parents\n    \n    def trajectory_guided_mutation(individual):\n        \"\"\"Mutate an individual using historical search trajectory for guidance.\"\"\"\n        if search_trajectory['individuals'] is not None:\n            historical_individual = search_trajectory['individuals'][np.random.randint(len(search_trajectory['individuals']))]\n            mutation_index = np.random.randint(N_P)\n            alpha = np.random.uniform(0.5, 1.5)\n            individual[mutation_index] = alpha * historical_individual[mutation_index] + (1 - alpha) * individual[mutation_index]\n        return np.clip(individual, xlb, xub)\n    \n    def create_new_population(ranked_individuals):\n        \"\"\"Create a new population using crossover and mutation operations.\"\"\"\n        new_population = []\n        while len(new_population) < POP_SIZE:\n            parent1, parent2 = select_parents(ranked_individuals)\n            offspring1, offspring2 = crossover(parent1, parent2)\n            offspring1 = mutate(offspring1)\n            offspring2 = mutate(offspring2)\n            new_population.extend([offspring1, offspring2])\n        return np.array(new_population[:POP_SIZE])\n    \n    def adaptively_guided_population():\n        \"\"\"Adaptively mutate the population using trajectory guidance and traditional mutation.\"\"\"\n        new_population = create_new_population(pops['individuals'])\n        for i in range(POP_SIZE):\n            if np.random.rand() < (current_gen / max_gen):\n                new_population[i] = trajectory_guided_mutation(new_population[i])\n            else:\n                new_population[i] = mutate(new_population[i])\n        return new_population\n    \n    new_pops = adaptively_guided_population()\n    return new_pops",
          "objective": -1.79249,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The algorithm generates the next population by combining tournament selection, differential evolution, and guided mutation based on historical search trajectory, with an adaptive strategy that varies between exploration and exploitation based on the current generation.\n    \"\"\"\n    import numpy as np\n    \n    def tournament_selection(population, tournament_size):\n        selected_indices = np.random.choice(range(len(population)), tournament_size, replace=False)\n        selected_individuals = population[selected_indices]\n        selected_rankings = pops['rankings'][selected_indices]\n        winner_index = selected_indices[np.argmin(selected_rankings)]\n        return population[winner_index]\n    \n    def differential_evolution(individual, population, F):\n        r1, r2, r3 = np.random.choice(range(len(population)), 3, replace=False)\n        x1, x2, x3 = population[r1], population[r2], population[r3]\n        mutant = np.clip(x1 + F * (x2 - x3), xlb, xub)\n        return mutant\n    \n    def guided_mutation(individual, trajectory, mutation_rate):\n        if trajectory['individuals'] is not None and len(trajectory['individuals']) > 0:\n            historical_best = trajectory['individuals'][np.argmin(trajectory['rankings'])]\n            mutant = individual + mutation_rate * (historical_best - individual)\n            return np.clip(mutant, xlb, xub)\n        else:\n            return individual\n    \n    def crossover(parent, donor, CR):\n        crossover_mask = np.random.rand(N_P) < CR\n        child = np.where(crossover_mask, donor, parent)\n        return child\n    \n    def create_new_individual(current_population, trajectory, gen_ratio):\n        parent = tournament_selection(current_population, tournament_size=2)\n        F = 0.5 * (1 + gen_ratio)  # Differential weight factor\n        CR = 0.5 * (1 - gen_ratio)  # Crossover probability\n        mutation_rate = 0.1 * (1 - gen_ratio)\n        \n        donor = differential_evolution(parent, current_population, F)\n        child = crossover(parent, donor, CR)\n        mutated_child = guided_mutation(child, trajectory, mutation_rate)\n        return mutated_child\n    \n    new_pops = np.empty((POP_SIZE, N_P))\n    current_population = pops['individuals']\n    gen_ratio = current_gen / max_gen  # A ratio to adjust strategies over generations\n    \n    for i in range(POP_SIZE):\n        new_pops[i] = create_new_individual(current_population, search_trajectory, gen_ratio)\n    \n    return new_pops",
          "objective": -21.53157,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    The algorithm combines differential evolution with a local search heuristic based on the search trajectory,\n    using adaptive mutation and crossover rates that evolve with the generation count.\n    \"\"\"\n\n    import numpy as np\n\n    def differential_evolution(individuals, rankings, cr, f):\n        def mutate(target_idx):\n            idxs = [idx for idx in range(len(individuals)) if idx != target_idx]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + f * (b - c), xlb, xub)\n            return mutant\n\n        def crossover(target, mutant):\n            cross_points = np.random.rand(N_P) < cr\n            trial = np.where(cross_points, mutant, target)\n            return trial\n\n        new_individuals = np.empty_like(individuals)\n        for i, target in enumerate(individuals):\n            mutant = mutate(i)\n            trial = crossover(target, mutant)\n            new_individuals[i] = trial\n        return new_individuals\n\n    def local_search(individuals, trajectory, search_intensity):\n        if trajectory['individuals'] is not None:\n            historical_best = trajectory['individuals'][np.argmin(trajectory['rankings'])]\n            for i, individual in enumerate(individuals):\n                if np.random.rand() < search_intensity:\n                    direction = historical_best - individual\n                    individuals[i] = np.clip(individual + np.random.rand(N_P) * direction, xlb, xub)\n        return individuals\n\n    def adaptive_rates(current_gen, max_gen):\n        cr = 0.5 + 0.5 * (current_gen / max_gen)\n        f = 0.5 * (1 - (current_gen / max_gen))\n        search_intensity = 0.1 + 0.4 * (current_gen / max_gen)\n        return cr, f, search_intensity\n\n    def next_population(pops):\n        cr, f, search_intensity = adaptive_rates(current_gen, max_gen)\n        new_individuals = differential_evolution(pops['individuals'], pops['rankings'], cr, f)\n        new_individuals = local_search(new_individuals, search_trajectory, search_intensity)\n        return new_individuals\n\n    new_pops = next_population(pops)\n    return new_pops",
          "objective": -22.1314,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    A novel multi-objective evolutionary algorithm that uses a combination of elitism, diversity preservation, \n    and adaptive mutation based on search history to generate the next population aiming for the Pareto-front.\n    \"\"\"\n    import numpy as np\n\n    def adaptive_mutation(individual, gen, max_gen, xlb, xub):\n        # Adaptive mutation strength based on generation\n        mutation_strength = (1 - (gen / max_gen)) * (xub - xlb)\n        return individual + np.random.uniform(-mutation_strength, mutation_strength, size=individual.shape)\n    \n    def crossover(parent1, parent2):\n        # Single point crossover\n        cross_point = np.random.randint(1, N_P)\n        child1 = np.concatenate((parent1[:cross_point], parent2[cross_point:]))\n        child2 = np.concatenate((parent2[:cross_point], parent1[cross_point:]))\n        return child1, child2\n\n    def select_parents(pops, POP_SIZE):\n        # Tournament selection\n        tournament_size = 2\n        selected_parents = []\n        for _ in range(POP_SIZE // 2):\n            candidates_idx = np.random.choice(range(POP_SIZE), tournament_size, replace=False)\n            candidates = pops['individuals'][candidates_idx]\n            candidate_ranks = pops['rankings'][candidates_idx]\n            winner_idx = candidates_idx[np.argmin(candidate_ranks)]\n            selected_parents.append(pops['individuals'][winner_idx])\n        return np.array(selected_parents)\n\n    def ensure_bounds(individual, xlb, xub):\n        return np.clip(individual, xlb, xub)\n\n    def generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub):\n        parents = select_parents(pops, POP_SIZE)\n        new_pops = []\n        for i in range(0, POP_SIZE, 2):\n            parent1, parent2 = parents[i % len(parents)], parents[(i + 1) % len(parents)]\n            child1, child2 = crossover(parent1, parent2)\n            child1 = adaptive_mutation(child1, current_gen, max_gen, xlb, xub)\n            child2 = adaptive_mutation(child2, current_gen, max_gen, xlb, xub)\n            child1 = ensure_bounds(child1, xlb, xub)\n            child2 = ensure_bounds(child2, xlb, xub)\n            new_pops.append(child1)\n            new_pops.append(child2)\n        return np.array(new_pops[:POP_SIZE])\n\n    new_pops = generate_new_population(pops, POP_SIZE, N_P, current_gen, max_gen, xlb, xub)\n    return new_pops",
          "objective": -31.99673,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    A novel multi-objective reproduction function that uses a combination of crossover, mutation, and historical search trajectory to generate the next population.\n    \"\"\"\n    import numpy as np\n\n    def crossover(parent1, parent2, crossover_rate=0.9):\n        if np.random.rand() < crossover_rate:\n            crossover_point = np.random.randint(1, N_P - 1)\n            child1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n            child2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])\n            return child1, child2\n        else:\n            return parent1.copy(), parent2.copy()\n\n    def mutate(individual, mutation_rate=0.1):\n        for i in range(N_P):\n            if np.random.rand() < mutation_rate:\n                individual[i] = individual[i] + np.random.randn() * (xub[i] - xlb[i]) * 0.1\n                individual[i] = np.clip(individual[i], xlb[i], xub[i])\n        return individual\n\n    def select_parents(population):\n        index1, index2 = np.random.choice(range(POP_SIZE), size=2, replace=False)\n        return population[index1], population[index2]\n\n    def generate_new_individuals(population):\n        new_population = []\n        while len(new_population) < POP_SIZE:\n            parent1, parent2 = select_parents(population)\n            child1, child2 = crossover(parent1, parent2)\n            child1 = mutate(child1)\n            child2 = mutate(child2)\n            new_population.append(child1)\n            if len(new_population) < POP_SIZE:\n                new_population.append(child2)\n        return np.array(new_population)\n\n    def use_search_trajectory(individuals, trajectory, alpha=0.5):\n        if trajectory['individuals'] is not None:\n            historical_individuals = trajectory['individuals']\n            selected_historical = historical_individuals[np.random.choice(historical_individuals.shape[0], size=POP_SIZE, replace=True)]\n            individuals = alpha * individuals + (1 - alpha) * selected_historical\n            individuals = np.clip(individuals, xlb, xub)\n        return individuals\n\n    # Main reproduction function\n    def next_population(pops, search_trajectory):\n        individuals = pops['individuals']\n        individuals = generate_new_individuals(individuals)\n        individuals = use_search_trajectory(individuals, search_trajectory)\n        return individuals\n\n    # Generate the next population\n    new_pops = next_population(pops, search_trajectory)\n\n    return new_pops",
          "objective": -45.78961,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        alpha = np.random.uniform(0, 1, size=(N_P,))\n        return alpha * parent1 + (1 - alpha) * parent2\n\n    def mutate(individual):\n        mutation_strength = (1 - (current_gen / max_gen)) * (xub - xlb)\n        mutation_vector = np.random.normal(0, mutation_strength, size=(N_P,))\n        return np.clip(individual + mutation_vector, xlb, xub)\n\n    def select_parents(ranked_population, tournament_size=2):\n        selected_indices = np.random.choice(range(POP_SIZE), size=tournament_size, replace=False)\n        tournament_pool = ranked_population[selected_indices]\n        parent_index = np.argmin(pops['rankings'][selected_indices])\n        return tournament_pool[parent_index]\n\n    def create_new_individual():\n        parent1 = select_parents(pops['individuals'])\n        parent2 = select_parents(pops['individuals'])\n        offspring = crossover(parent1, parent2)\n        offspring = mutate(offspring)\n        return offspring\n\n    new_pops = np.array([create_new_individual() for _ in range(POP_SIZE)])\n    return new_pops",
          "objective": -47.15939,
          "other_inf": null
     },
     {
          "algorithm": "'individuals': new_pops, 'rankings': np.zeros(POP_SIZE)",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def mutate(individual, mutation_rate, xlb, xub):\n        mutant = individual + mutation_rate * (xub - xlb) * np.random.randn(*individual.shape)\n        return np.clip(mutant, xlb, xub)\n\n    def crossover(parent1, parent2, crossover_rate):\n        rand_mask = np.random.rand(*parent1.shape) < crossover_rate\n        offspring = np.where(rand_mask, parent1, parent2)\n        return offspring\n\n    def select_parents(pops, tournament_size):\n        tournament_indices = np.random.randint(0, pops['individuals'].shape[0], tournament_size)\n        tournament_individuals = pops['individuals'][tournament_indices]\n        tournament_rankings = pops['rankings'][tournament_indices]\n        parent_index = tournament_indices[np.argmin(tournament_rankings)]\n        return pops['individuals'][parent_index]\n\n    mutation_rate = 1.0 / np.sqrt(N_P)\n    crossover_rate = 0.9\n    tournament_size = 2\n    new_pops = np.empty((POP_SIZE, N_P))\n\n    for i in range(POP_SIZE):\n        parent1 = select_parents(pops, tournament_size)\n        parent2 = select_parents(pops, tournament_size)\n        offspring = crossover(parent1, parent2, crossover_rate)\n        offspring = mutate(offspring, mutation_rate, xlb, xub)\n        new_pops[i] = offspring\n\n    return new_pops",
          "objective": -49.72555,
          "other_inf": null
     },
     {
          "algorithm": "A novel evolutionary reproduction function that combines exploration and exploitation by blending crossover,\n    mutation, and historical search trajectory information to generate a new population aiming at the Pareto-front.}\n    \"\"\"\n\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        # Simulated binary crossover (SBX)\n        beta = np.random.uniform(0, 1, size=(N_P,))\n        child = 0.5 * ((1 + beta) * parent1 + (1 - beta) * parent2)\n        return child\n\n    def mutation(individual):\n        # Polynomial mutation\n        eta_m = 20\n        delta = np.random.uniform(0, 1, size=(N_P,))\n        mut_pow = 1.0 / (eta_m + 1.0)\n        mask = delta < 0.5\n        delta_q = mask * (2.0 * delta) ** mut_pow - 1.0 + (~mask) * (1 - (2.0 * (1 - delta)) ** mut_pow)\n        mutant = individual + delta_q * (xub - xlb)\n        return mutant\n\n    def select_parents(ranked_individuals):\n        # Tournament selection\n        participants = np.random.choice(ranked_individuals.shape[0], size=2, replace=False)\n        if pops['rankings'][participants[0]] < pops['rankings'][participants[1]]:\n            return ranked_individuals[participants[0]]\n        else:\n            return ranked_individuals[participants[1]]\n\n    def create_new_individual():\n        parent1 = select_parents(pops['individuals'])\n        parent2 = select_parents(pops['individuals'])\n        child = crossover(parent1, parent2)\n        mutant = mutation(child)\n        return np.clip(mutant, xlb, xub)\n\n    def historical_guidance(individual):\n        # Use historical search trajectory to guide mutation\n        if search_trajectory['individuals'] is not None:\n            historical_sample = search_trajectory['individuals'][np.random.choice(search_trajectory['individuals'].shape[0])]\n            return mutation(0.5 * (individual + historical_sample))\n        else:\n            return mutation(individual)\n\n    new_pops = np.empty((POP_SIZE, N_P))\n    for i in range(POP_SIZE):\n        if np.random.rand() < 0.5:\n            new_pops[i] = create_new_individual()\n        else:\n            new_pops[i] = historical_guidance(pops['individuals'][i])\n\n    return {'individuals': new_pops",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    {A novel evolutionary reproduction function that combines exploration and exploitation by blending crossover,\n    mutation, and historical search trajectory information to generate a new population aiming at the Pareto-front.}\n    \"\"\"\n\n    import numpy as np\n\n    def crossover(parent1, parent2):\n        # Simulated binary crossover (SBX)\n        beta = np.random.uniform(0, 1, size=(N_P,))\n        child = 0.5 * ((1 + beta) * parent1 + (1 - beta) * parent2)\n        return child\n\n    def mutation(individual):\n        # Polynomial mutation\n        eta_m = 20\n        delta = np.random.uniform(0, 1, size=(N_P,))\n        mut_pow = 1.0 / (eta_m + 1.0)\n        mask = delta < 0.5\n        delta_q = mask * (2.0 * delta) ** mut_pow - 1.0 + (~mask) * (1 - (2.0 * (1 - delta)) ** mut_pow)\n        mutant = individual + delta_q * (xub - xlb)\n        return mutant\n\n    def select_parents(ranked_individuals):\n        # Tournament selection\n        participants = np.random.choice(ranked_individuals.shape[0], size=2, replace=False)\n        if pops['rankings'][participants[0]] < pops['rankings'][participants[1]]:\n            return ranked_individuals[participants[0]]\n        else:\n            return ranked_individuals[participants[1]]\n\n    def create_new_individual():\n        parent1 = select_parents(pops['individuals'])\n        parent2 = select_parents(pops['individuals'])\n        child = crossover(parent1, parent2)\n        mutant = mutation(child)\n        return np.clip(mutant, xlb, xub)\n\n    def historical_guidance(individual):\n        # Use historical search trajectory to guide mutation\n        if search_trajectory['individuals'] is not None:\n            historical_sample = search_trajectory['individuals'][np.random.choice(search_trajectory['individuals'].shape[0])]\n            return mutation(0.5 * (individual + historical_sample))\n        else:\n            return mutation(individual)\n\n    new_pops = np.empty((POP_SIZE, N_P))\n    for i in range(POP_SIZE):\n        if np.random.rand() < 0.5:\n            new_pops[i] = create_new_individual()\n        else:\n            new_pops[i] = historical_guidance(pops['individuals'][i])\n\n    return new_pops",
          "objective": -54.08353,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    \"\"\"\n    A novel reproduction function that combines differential evolution with a local search heuristic,\n    guided by the search trajectory, to generate the next population for a continuous multi-objective optimization problem.\n    \"\"\"\n    import numpy as np\n    \n    def differential_evolution(individuals, F=0.8):\n        # DE/rand/1/bin implementation\n        new_individuals = np.copy(individuals)\n        for i in range(POP_SIZE):\n            idxs = [idx for idx in range(POP_SIZE) if idx != i]\n            a, b, c = individuals[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), xlb, xub)\n            cross_points = np.random.rand(N_P) < 0.9\n            trial = np.where(cross_points, mutant, individuals[i])\n            new_individuals[i] = trial\n        return new_individuals\n    \n    def local_search(individuals, search_traj, sigma=0.1):\n        # Gaussian perturbation based on search trajectory\n        if search_traj['individuals'] is not None:\n            mean_traj = np.mean(search_traj['individuals'], axis=0)\n            perturbation = sigma * np.random.randn(POP_SIZE, N_P) + mean_traj\n        else:\n            perturbation = sigma * np.random.randn(POP_SIZE, N_P)\n        return np.clip(individuals + perturbation, xlb, xub)\n    \n    def select_next_population(individuals, rankings, new_individuals):\n        combined_population = np.vstack((individuals, new_individuals))\n        combined_rankings = np.hstack((rankings, rankings))  # Assuming same ranking for simplicity\n        sorted_indices = np.argsort(combined_rankings)\n        return combined_population[sorted_indices[:POP_SIZE]]\n    \n    # Main steps of the algorithm\n    individuals = pops['individuals']\n    rankings = pops['rankings']\n    de_individuals = differential_evolution(individuals)\n    ls_individuals = local_search(individuals, search_trajectory)\n    new_pops = select_next_population(individuals, rankings, ls_individuals)\n    \n    return new_pops",
          "objective": -54.94133,
          "other_inf": null
     }
]
[
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    # Use differential evolution-based crossover combined with a self-adaptive mutation strategy\n    \n    def differential_mutation(individuals, f=0.8):\n        \"\"\" Mutation operation in Differential Evolution. \"\"\"\n        mutated = np.zeros_like(individuals)\n        num_individuals = len(individuals)\n        for i in range(num_individuals):\n            idxs = np.random.choice(num_individuals, 3, replace=False)\n            a, b, c = individuals[idxs[0]], individuals[idxs[1]], individuals[idxs[2]]\n            mutated[i] = a + f * (b - c)\n        return mutated\n\n    def self_adaptive_mutation(individuals, tau=1.0):\n        \"\"\" Apply mutation influenced by the current generation. \"\"\"\n        mutation_strength = np.exp(-tau * current_gen / max_gen)\n        for i in range(len(individuals)):\n            for j in range(N_P):\n                if np.random.rand() < 0.1:  # mutation probability\n                    individuals[i, j] += mutation_strength * np.random.randn()\n                    individuals[i, j] = np.clip(individuals[i, j], xlb[j], xub[j])\n        return individuals\n    \n    def elite_preservation(strongest, elite_size):\n        \"\"\" Preserve the best solutions \"\"\"\n        return strongest[:elite_size]\n\n    # Parameters\n    elite_size = POP_SIZE // 5  # 20% of the population size\n    \n    # Preserve elites directly to the new population\n    elites = elite_preservation(pops['individuals'], elite_size)\n\n    # Apply differential mutation to generate donors\n    donors = differential_mutation(pops['individuals'])\n\n    # Recombine (crossover) with existing population\n    recombined = np.where(np.random.rand(POP_SIZE, N_P) < 0.5, pops['individuals'], donors)\n\n    # Mutation for diversity\n    new_individuals = self_adaptive_mutation(recombined)\n\n    # Elitism: Combine elite individuals with mutants\n    new_pops = np.vstack([elites, new_individuals[elite_size:]])\n\n    # Ensure population size remains constant\n    np.random.shuffle(new_pops)  # Shuffle to mix elites with new individuals\n\n    return new_pops",
          "objective": -0.59999,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def tournament_selection(individuals, rankings, selection_size):\n        \"\"\" Select individuals based on a tournament selection process. \"\"\"\n        tournament_results = np.empty((selection_size, N_P))\n        for i in range(selection_size):\n            contenders = np.random.choice(len(individuals), 3, replace=False)\n            winner = contenders[np.argmin(rankings[contenders])]\n            tournament_results[i] = individuals[winner]\n        return tournament_results\n    \n    def gaussian_mutation(individuals, mutation_rate, mutation_scale):\n        \"\"\" Apply Gaussian mutation based on a predefined rate and scale. \"\"\"\n        num_mutations = int(mutation_rate * len(individuals) * N_P)\n        for _ in range(num_mutations):\n            ind = np.random.randint(len(individuals))\n            gene = np.random.randint(N_P)\n            individuals[ind, gene] += np.random.randn() * mutation_scale\n            individuals[ind, gene] = np.clip(individuals[ind, gene], xlb[gene], xub[gene])\n        return individuals\n    \n    def simple_crossover(parents, num_offspring):\n        \"\"\" Perform a simple one-point crossover. \"\"\"\n        offspring = np.empty((num_offspring, N_P))\n        for i in range(num_offspring):\n            p1, p2 = np.random.choice(len(parents), 2, replace=False)\n            point = np.random.randint(1, N_P)\n            offspring[i, :point] = parents[p1, :point]\n            offspring[i, point:] = parents[p2, point:]\n        return offspring\n    \n    elite_count = int(POP_SIZE * 0.2)\n    elites = pops['individuals'][:elite_count]\n    \n    selected_for_crossover = tournament_selection(pops['individuals'], pops['rankings'], POP_SIZE - elite_count)\n    offsprings = simple_crossover(selected_for_crossover, POP_SIZE - elite_count)\n    \n    mutated_offsprings = gaussian_mutation(offsprings, mutation_rate=0.05, mutation_scale=0.1 * (1 - current_gen/max_gen))\n    \n    new_pops = np.vstack([elites, mutated_offsprings])\n    np.random.shuffle(new_pops)\n    \n    return new_pops",
          "objective": -2.35929,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    # Novel reproduction function: Quantum-inspired crossover with adaptive mutation\n    def quantum_inspired_crossover(individuals, rankings, lb, ub):\n        CR = 0.1 + 0.9 * (current_gen / max_gen)  # Crossover Probability\n        F = 0.5 + 0.5 * np.cos(np.pi * current_gen / max_gen)  # Differential Weight\n        best_idx = np.argmin(rankings)\n        best_individual = individuals[best_idx]\n\n        mutated_population = np.zeros_like(individuals)\n        for i, individual in enumerate(individuals):\n            indices = np.random.choice(POP_SIZE, 3, replace=False)\n            if i in indices:\n                indices = (indices + 1) % POP_SIZE  # to avoid self-inclusion\n            a, b, c = individuals[indices]\n            quantum_prob = np.random.rand()\n            if quantum_prob < 0.5:\n                mutant = a + F * (b - c)\n            else:\n                mutant = best_individual + F * (b - c)\n            crossover = np.random.rand(N_P) < CR\n            offspring = np.where(crossover, mutant, individual)\n            mutated_population[i] = np.clip(offspring, lb, ub)\n        \n        return mutated_population\n\n    new_pops = quantum_inspired_crossover(pops['individuals'], pops['rankings'], xlb, xub)\n    return new_pops",
          "objective": -2.51367,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def differential_evolution(parents, F=0.8):\n        \"\"\"Generates a new individual using Differential Evolution strategy.\"\"\"\n        indices = np.random.choice(len(parents), 3, replace=False)\n        x1, x2, x3 = parents[indices]\n        mutant = np.clip(x1 + F * (x2 - x3), xlb, xub)\n        return mutant\n\n    def adaptive_crossover(target, mutant, CR=0.5):\n        \"\"\"Performs adaptive crossover between target and mutant.\"\"\"\n        trial = np.where(np.random.rand(N_P) < CR, mutant, target)\n        return trial\n    \n    # Parameters for adaptation\n    CR = 0.1 + 0.5 * (current_gen / max_gen)\n    F = 0.5 + 0.4 * (current_gen / max_gen)\n\n    # Form new population\n    new_pops = np.zeros_like(pops['individuals'])\n    sorted_indices = np.argsort(pops['rankings'])  # Sort based on ranking\n    sorted_population = pops['individuals'][sorted_indices]\n    \n    for i in range(POP_SIZE):\n        mutant = differential_evolution(sorted_population, F)\n        new_pops[i] = adaptive_crossover(pops['individuals'][i], mutant, CR)\n    \n    return new_pops",
          "objective": -3.7183,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    # (Combining differential evolution with dynamic adaptive mutation and historical best-reference crossover)\n    def adaptive_differential_evolution(individuals, rankings, lb, ub):\n        CR = 0.1 + 0.8 * (current_gen / max_gen)  # Crossover Probability\n        F = 0.5 + 0.5 * np.sin(np.pi * current_gen / max_gen)  # Differential Weight\n        best_idx = np.argmin(rankings)\n        best_individual = individuals[best_idx]\n\n        mutated_population = np.zeros_like(individuals)\n        for i, individual in enumerate(individuals):\n            indices = np.random.choice(POP_SIZE, 3, replace=False)\n            if i in indices:\n                indices = (indices + 1) % POP_SIZE  # to avoid self-inclusion\n            a, b, c = individuals[indices]\n            mutant = best_individual + F * (b - c)\n            crossover = np.random.rand(N_P) < CR\n            offspring = np.where(crossover, mutant, individual)\n            mutated_population[i] = np.clip(offspring, lb, ub)\n        \n        return mutated_population\n\n    new_pops = adaptive_differential_evolution(pops['individuals'], pops['rankings'], xlb, xub)\n    return new_pops",
          "objective": -5.16416,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    # Adaptive mutation that factors in generational distance\n    def focused_mutate(individual, top_performer, mutation_scale=0.3):\n        # Weight more towards top performers as generations go by\n        beta = np.random.normal(0, 1, size=individual.shape)\n        weight = np.exp(-current_gen / max_gen)\n        mutation_vector = mutation_scale * (top_performer - individual) * weight + beta * (1 - weight)\n        return individual + mutation_vector\n\n    # Biased crossover giving preference to better-ranked individuals\n    def biased_crossover(parent1, parent2, rank1, rank2):\n        # Higher chance to pick characteristics from better-ranked parent\n        p = rank1 / (rank1 + rank2) if rank1 + rank2 != 0 else 0.5\n        crossover_mask = np.random.rand(N_P) < p\n        offspring = np.where(crossover_mask, parent1, parent2)\n        return offspring\n\n    # Initialize new population array\n    new_pops = np.zeros((POP_SIZE, N_P))\n\n    # Ensure there are previous individuals to sample from\n    history_available = search_trajectory['individuals'] is not None and len(search_trajectory['individuals']) > 0\n\n    for i in range(POP_SIZE):\n        idx1, idx2 = np.random.randint(0, POP_SIZE, size=2)\n        parent1 = pops['individuals'][idx1]\n        parent2 = pops['individuals'][idx2]\n        rank1 = pops['rankings'][idx1]\n        rank2 = pops['rankings'][idx2]\n\n        if np.random.rand() < 0.5:\n            # Perform biased crossover\n            new_pops[i] = biased_crossover(parent1, parent2, rank1, rank2)\n        else:\n            # Perform focused mutation based on the best available individual or a historical point\n            if history_available and np.random.rand() < 0.5:\n                history_idx = np.random.choice(len(search_trajectory['individuals']))\n                ref_individual = search_trajectory['individuals'][history_idx]\n            else:\n                ref_individual = pops['individuals'][np.argmin(pops['rankings'])]\n\n            new_pops[i] = focused_mutate(parent1, ref_individual)\n\n        # Clip to stay within bounds\n        new_pops[i] = np.clip(new_pops[i], xlb, xub)\n\n    return new_pops",
          "objective": -5.63161,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def uniform_mutation(individual, lb, ub, mutation_rate):\n        \"\"\"Mutates individual vector elements using a uniform random distribution.\"\"\"\n        mutant = np.copy(individual)\n        for i in range(len(mutant)):\n            if np.random.random() < mutation_rate:\n                mutant[i] = np.random.uniform(lb[i], ub[i])\n        return mutant\n\n    def crossover(parent1, parent2, crossover_rate):\n        \"\"\"Performs uniform crossover between two parents.\"\"\"\n        child = np.copy(parent1)\n        for i in range(len(child)):\n            if np.random.random() < crossover_rate:\n                child[i] = parent2[i]\n        return child\n\n    def select_parents(population):\n        \"\"\"Select parents for crossover using tournament selection.\"\"\"\n        # Tournament size is fixed to 2 for simplicity\n        idx1, idx2 = np.random.randint(0, len(population), 2)\n        if pops['rankings'][idx1] < pops['rankings'][idx2]:\n            parent1 = population[idx1]\n        else:\n            parent1 = population[idx2]\n\n        idx3, idx4 = np.random.randint(0, len(population), 2)\n        if pops['rankings'][idx3] < pops['rankings'][idx4]:\n            parent2 = population[idx3]\n        else:\n            parent2 = population[idx4]\n        \n        return parent1, parent2\n\n    mutation_rate = 0.1 + 0.9 * (current_gen / max_gen)  # Increase mutation rate over time\n    crossover_rate = 0.9 - 0.7 * (current_gen / max_gen)  # Decrease crossover rate over time\n\n    new_pops = np.zeros_like(pops['individuals'])\n\n    # Generate new population\n    for i in range(POP_SIZE):\n        parent1, parent2 = select_parents(pops['individuals'])\n        child = crossover(parent1, parent2, crossover_rate)\n        child = uniform_mutation(child, xlb, xub, mutation_rate)\n        new_pops[i] = child\n\n    return new_pops",
          "objective": -7.52235,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def dynamic_mutation(individual, phase):\n        # Dynamic mutation based on a Gaussian mutation and normalized phase\n        amplitude = 0.1 + 0.3 * (1 - phase)  # Decreases as phase increases\n        mutation_scale = np.abs(np.random.normal(0, amplitude, size=N_P))\n        mutation_direction = np.random.choice([-1, 1], size=N_P)\n        mutated_individual = individual + mutation_direction * mutation_scale\n        return np.clip(mutated_individual, xlb, xub)\n    \n    def uniform_crossover(individual1, individual2):\n        # Uniform crossover that mixes genes from two parents based on random mask\n        mask = np.random.rand(N_P) > 0.5  # Uniformly random crossover mask\n        offspring = np.where(mask, individual1, individual2)\n        return offspring\n\n    def evolve_population():\n        new_population = []\n        for i in range(POP_SIZE):\n            if np.random.rand() < 0.6:  # Favor crossover to create diversity\n                # Select another random individual\n                other_idx = np.random.randint(POP_SIZE)\n                while other_idx == i:\n                    other_idx = np.random.randint(POP_SIZE)\n                selected = uniform_crossover(pops['individuals'][i], pops['individuals'][other_idx])\n            else:\n                selected = dynamic_mutation(pops['individuals'][i], current_gen / max_gen)\n            new_population.append(selected)\n        return np.array(new_population)\n\n    new_pops = evolve_population()\n    return new_pops",
          "objective": -9.09186,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def adaptive_random_crossover(individuals, num_offspring):\n        \"\"\" Generate offspring by a random adaptive crossover mechanism based on current population statistics. \"\"\"\n        offspring = np.empty((num_offspring, N_P))\n        mean_vector = np.mean(individuals, axis=0)\n        std_deviation = np.std(individuals, axis=0)\n        \n        for i in range(num_offspring):\n            idx1, idx2 = np.random.choice(len(individuals), 2, replace=False)\n            crossover_point = np.random.rand(N_P) > 0.5\n            offspring[i] = np.where(crossover_point, individuals[idx1], individuals[idx2])\n            # Introduce some variation based on population distribution\n            offspring[i] += np.random.randn(N_P) * std_deviation * np.exp(-0.1 * current_gen)\n            offspring[i] = np.clip(offspring[i], xlb, xub)\n        return offspring\n\n    def fitness_proportionate_selection(individuals, rankings, num_selected):\n        \"\"\" Select individuals based on their fitness proportionately. \"\"\"\n        min_rank = np.min(rankings)\n        probabilities = 1 / (rankings - min_rank + 1)\n        probabilities /= probabilities.sum()\n        selected_indices = np.random.choice(len(individuals), num_selected, p=probabilities, replace=False)\n        return individuals[selected_indices]\n    \n    elite_size = POP_SIZE // 5  # Keeping a fraction of the population as elites\n    elites = pops['individuals'][:elite_size]\n    \n    # Using Fitness Proportionate Selection for preserving some good but not necessarily elite individuals\n    selected_individuals = fitness_proportionate_selection(pops['individuals'], pops['rankings'], POP_SIZE - elite_size)\n    \n    # Crossover to generate new individuals\n    offsprings = adaptive_random_crossover(selected_individuals, POP_SIZE - elite_size)\n    \n    # Creating new population\n    new_pops = np.vstack([elites, offsprings])\n    np.random.shuffle(new_pops)  # Ensure mixing of the new population\n    \n    return new_pops",
          "objective": -10.50885,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    # Novel algorithm: Enhanced Adaptive Mutation with Historical Influence Crossover\n    def enhanced_adaptive_mutation_with_historical_crossover(individuals, rankings, lb, ub, trajectory):\n        CR = 0.2 + 0.7 * np.cos(np.pi * current_gen / max_gen)  # Crossover Probability changes over generations\n        F = 0.3 + 0.7 * np.exp(-0.05 * (max_gen - current_gen))  # Adjusts mutation factor dynamically\n        historical_bests = trajectory['individuals']\n        \n        if historical_bests is not None and len(historical_bests) > 2:\n            historical_bests = historical_bests[np.random.choice(len(historical_bests), 2, replace=False)]\n        \n        mutated_population = np.zeros_like(individuals)\n        for i, individual in enumerate(individuals):\n            indices = np.random.choice(POP_SIZE, 3, replace=False)\n            if i in indices:\n                indices = (indices + 1) % POP_SIZE  # Ensure no self-inclusion in mutation targets\n            a, b, c = individuals[indices]\n            mutant = individual + F * (b - c)\n            if historical_bests is not None:\n                historical_influence = historical_bests[0] + F * (historical_bests[1] - individual)\n                mutant = 0.5 * mutant + 0.5 * historical_influence\n            crossover = np.random.rand(N_P) < CR\n            offspring = np.where(crossover, mutant, individual)\n            mutated_population[i] = np.clip(offspring, lb, ub)\n        \n        return mutated_population\n\n    new_pops = enhanced_adaptive_mutation_with_historical_crossover(pops['individuals'], pops['rankings'], xlb, xub, search_trajectory)\n    return new_pops",
          "objective": -11.39194,
          "other_inf": null
     }
]
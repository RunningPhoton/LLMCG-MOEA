[
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    # Adaptive mutation that factors in generational distance\n    def focused_mutate(individual, top_performer, mutation_scale=0.3):\n        # Weight more towards top performers as generations go by\n        beta = np.random.normal(0, 1, size=individual.shape)\n        weight = np.exp(-current_gen / max_gen)\n        mutation_vector = mutation_scale * (top_performer - individual) * weight + beta * (1 - weight)\n        return individual + mutation_vector\n\n    # Biased crossover giving preference to better-ranked individuals\n    def biased_crossover(parent1, parent2, rank1, rank2):\n        # Higher chance to pick characteristics from better-ranked parent\n        p = rank1 / (rank1 + rank2) if rank1 + rank2 != 0 else 0.5\n        crossover_mask = np.random.rand(N_P) < p\n        offspring = np.where(crossover_mask, parent1, parent2)\n        return offspring\n\n    # Initialize new population array\n    new_pops = np.zeros((POP_SIZE, N_P))\n\n    # Ensure there are previous individuals to sample from\n    history_available = search_trajectory['individuals'] is not None and len(search_trajectory['individuals']) > 0\n\n    for i in range(POP_SIZE):\n        idx1, idx2 = np.random.randint(0, POP_SIZE, size=2)\n        parent1 = pops['individuals'][idx1]\n        parent2 = pops['individuals'][idx2]\n        rank1 = pops['rankings'][idx1]\n        rank2 = pops['rankings'][idx2]\n\n        if np.random.rand() < 0.5:\n            # Perform biased crossover\n            new_pops[i] = biased_crossover(parent1, parent2, rank1, rank2)\n        else:\n            # Perform focused mutation based on the best available individual or a historical point\n            if history_available and np.random.rand() < 0.5:\n                history_idx = np.random.choice(len(search_trajectory['individuals']))\n                ref_individual = search_trajectory['individuals'][history_idx]\n            else:\n                ref_individual = pops['individuals'][np.argmin(pops['rankings'])]\n\n            new_pops[i] = focused_mutate(parent1, ref_individual)\n\n        # Clip to stay within bounds\n        new_pops[i] = np.clip(new_pops[i], xlb, xub)\n\n    return new_pops",
          "objective": -5.63161,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def uniform_mutation(individual, lb, ub, mutation_rate):\n        \"\"\"Mutates individual vector elements using a uniform random distribution.\"\"\"\n        mutant = np.copy(individual)\n        for i in range(len(mutant)):\n            if np.random.random() < mutation_rate:\n                mutant[i] = np.random.uniform(lb[i], ub[i])\n        return mutant\n\n    def crossover(parent1, parent2, crossover_rate):\n        \"\"\"Performs uniform crossover between two parents.\"\"\"\n        child = np.copy(parent1)\n        for i in range(len(child)):\n            if np.random.random() < crossover_rate:\n                child[i] = parent2[i]\n        return child\n\n    def select_parents(population):\n        \"\"\"Select parents for crossover using tournament selection.\"\"\"\n        # Tournament size is fixed to 2 for simplicity\n        idx1, idx2 = np.random.randint(0, len(population), 2)\n        if pops['rankings'][idx1] < pops['rankings'][idx2]:\n            parent1 = population[idx1]\n        else:\n            parent1 = population[idx2]\n\n        idx3, idx4 = np.random.randint(0, len(population), 2)\n        if pops['rankings'][idx3] < pops['rankings'][idx4]:\n            parent2 = population[idx3]\n        else:\n            parent2 = population[idx4]\n        \n        return parent1, parent2\n\n    mutation_rate = 0.1 + 0.9 * (current_gen / max_gen)  # Increase mutation rate over time\n    crossover_rate = 0.9 - 0.7 * (current_gen / max_gen)  # Decrease crossover rate over time\n\n    new_pops = np.zeros_like(pops['individuals'])\n\n    # Generate new population\n    for i in range(POP_SIZE):\n        parent1, parent2 = select_parents(pops['individuals'])\n        child = crossover(parent1, parent2, crossover_rate)\n        child = uniform_mutation(child, xlb, xub, mutation_rate)\n        new_pops[i] = child\n\n    return new_pops",
          "objective": -7.52235,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def adaptive_random_crossover(individuals, num_offspring):\n        \"\"\" Generate offspring by a random adaptive crossover mechanism based on current population statistics. \"\"\"\n        offspring = np.empty((num_offspring, N_P))\n        mean_vector = np.mean(individuals, axis=0)\n        std_deviation = np.std(individuals, axis=0)\n        \n        for i in range(num_offspring):\n            idx1, idx2 = np.random.choice(len(individuals), 2, replace=False)\n            crossover_point = np.random.rand(N_P) > 0.5\n            offspring[i] = np.where(crossover_point, individuals[idx1], individuals[idx2])\n            # Introduce some variation based on population distribution\n            offspring[i] += np.random.randn(N_P) * std_deviation * np.exp(-0.1 * current_gen)\n            offspring[i] = np.clip(offspring[i], xlb, xub)\n        return offspring\n\n    def fitness_proportionate_selection(individuals, rankings, num_selected):\n        \"\"\" Select individuals based on their fitness proportionately. \"\"\"\n        min_rank = np.min(rankings)\n        probabilities = 1 / (rankings - min_rank + 1)\n        probabilities /= probabilities.sum()\n        selected_indices = np.random.choice(len(individuals), num_selected, p=probabilities, replace=False)\n        return individuals[selected_indices]\n    \n    elite_size = POP_SIZE // 5  # Keeping a fraction of the population as elites\n    elites = pops['individuals'][:elite_size]\n    \n    # Using Fitness Proportionate Selection for preserving some good but not necessarily elite individuals\n    selected_individuals = fitness_proportionate_selection(pops['individuals'], pops['rankings'], POP_SIZE - elite_size)\n    \n    # Crossover to generate new individuals\n    offsprings = adaptive_random_crossover(selected_individuals, POP_SIZE - elite_size)\n    \n    # Creating new population\n    new_pops = np.vstack([elites, offsprings])\n    np.random.shuffle(new_pops)  # Ensure mixing of the new population\n    \n    return new_pops",
          "objective": -10.50885,
          "other_inf": null
     },
     {
          "algorithm": "My novel reproduction function leverages spatial crossover driven by fitness that enhances exploration and self-adaptive mutation based on the genetic diversity in the population, aiming to balance exploration and exploitation throughout the evolution process.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def spatial_crossover(parent1, parent2, alpha):\n        # Linear Combination Crossover\n        return alpha * parent1 + (1 - alpha) * parent2\n\n    def self_adaptive_mutation(individual):\n        diversity_factor = np.std(pops['individuals'], axis=0) ** 2\n        mutation_strength = 0.1 * (1 - current_gen / max_gen) * diversity_factor\n        mutation = np.random.normal(0, mutation_strength)\n        return np.clip(individual + mutation, xlb, xub)\n\n    def calculate_fitness(individual):\n        # Proxy for evaluating fitness, can be replaced with actual objective function evaluation in practice.\n        return np.sum(individual)\n\n    new_pops = np.zeros((POP_SIZE, N_P))\n\n    # Generate new population\n    for i in range(POP_SIZE):\n        # Select two parents based on a spatial proximity driven by fitness\n        fitnesses = np.array([calculate_fitness(ind) for ind in pops['individuals']])\n        parent_indices = np.argsort(fitnesses)\n        mid_point = np.random.randint(POP_SIZE)\n        parent1 = pops['individuals'][parent_indices[mid_point]]\n        parent2 = pops['individuals'][parent_indices[(mid_point + 1) % POP_SIZE]]\n        \n        # Uniformly pick crossover weight\n        alpha = np.random.uniform(0, 1)\n        offspring = spatial_crossover(parent1, parent2, alpha)\n        \n        # Mutation with self-adaptation\n        offspring = self_adaptive_mutation(offspring)\n        \n        # Assign offspring to new population\n        new_pops[i] = offspring\n    \n    return new_pops",
          "objective": -11.92114,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def elitism_selection(individuals, rankings, elite_count):\n        return individuals[:elite_count]\n    \n    def social_learning(individuals, elite_individuals):\n        social_f = 0.1 + (0.9 * current_gen / max_gen)  # Social factor increasing with generation count\n        new_individuals = np.empty_like(individuals)\n        for i in range(len(individuals)):\n            rand_elite = elite_individuals[np.random.randint(len(elite_individuals))]\n            new_individuals[i] = individuals[i] * (1 - social_f) + rand_elite * social_f\n        return new_individuals\n        \n    def local_search(individuals):\n        local_mutation_extent = 0.05 * (1 - current_gen / max_gen)  # Decreasing factor\n        mutation_vectors = np.random.normal(0, local_mutation_extent, individuals.shape)\n        return np.clip(individuals + mutation_vectors, xlb, xub)\n    \n    elite_size = max(1, POP_SIZE // 10)  # Dynamic allocation of elite fraction\n    elite_individuals = elitism_selection(pops['individuals'], pops['rankings'], elite_size)\n    \n    # Social learning from elites\n    social_learned = social_learning(pops['individuals'][elite_size:], elite_individuals)\n    \n    # Local search for new variations\n    new_pops = local_search(social_learned)\n    \n    # Merge elites back into the new population\n    new_pops = np.vstack((elite_individuals, new_pops))\n    \n    return new_pops",
          "objective": -12.55888,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n  \n    def adaptive_blending(individual1, individual2, generation_phase):\n        # Blend two individuals based on the phase of generation\n        weight1 = 0.5 + 0.5 * np.sin(np.pi * generation_phase)\n        return individual1 * weight1 + individual2 * (1 - weight1)\n        \n    def dynamic_mutation(individual):\n        # Adaptive mutation based on the generation\n        sigma = 0.1 * (1 - current_gen / max_gen)\n        mutation = np.random.normal(0, sigma, N_P)\n        return np.clip(individual + mutation, xlb, xub)\n    \n    def tournament_selection():\n        # Select two different random individuals\n        i, j = np.random.choice(POP_SIZE, 2, replace=False)\n        if pops['rankings'][i] < pops['rankings'][j]:\n            return pops['individuals'][i].copy(), pops['individuals'][j].copy()\n        else:\n            return pops['individuals'][j].copy(), pops['individuals'][i].copy()\n    \n    def evolve_population():\n        new_population = []\n        for i in range(POP_SIZE):\n            parent1, parent2 = tournament_selection()\n            if np.random.rand() < 0.7:\n                offspring = adaptive_blending(parent1, parent2, current_gen / max_gen)\n            else:\n                offspring = dynamic_mutation(parent1)\n            new_population.append(offspring)\n        return np.array(new_population)\n    \n    new_pops = evolve_population()\n    return new_pops",
          "objective": -14.09109,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def balanced_search(individual, phase):\n        # Linearly decrease local exploration and increase global exploitation\n        local_ratio = 1 - phase\n        global_ratio = phase\n        step_local = 0.05 * np.sqrt(1 - phase)\n        step_global = 0.2 + 0.1 * np.sin(np.pi * current_gen / max_gen)\n\n        local_pert = np.random.normal(0, step_local, size=N_P)\n        global_pert = np.random.normal(0, step_global, size=N_P)\n        \n        new_individual = individual + local_ratio * local_pert + global_ratio * global_pert\n        return np.clip(new_individual, xlb, xub)\n\n    def crossover(individual1, individual2):\n        # Single-point crossover\n        point = np.random.randint(N_P)\n        offspring = np.concatenate([individual1[:point], individual2[point:]])\n        return offspring\n\n    def evolve_population():\n        new_population = []\n        for i in range(POP_SIZE):\n            if np.random.rand() < 0.5:  # Choose whether to mutate or crossover\n                selected = crossover(pops['individuals'][i], pops['individuals'][np.random.randint(POP_SIZE)])\n            else:\n                selected = balanced_search(pops['individuals'][i], current_gen / max_gen)\n            new_population.append(selected)\n        return np.array(new_population)\n\n    new_pops = evolve_population()\n    return new_pops",
          "objective": -14.64913,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def adaptive_local_search(individual, gen_progress):\n        # Adjust the step size based on the generation progress\n        step_size = 0.1 * (1 - gen_progress) ** 2\n        perturbations = np.random.normal(0, step_size, size=N_P)\n        return np.clip(individual + perturbations, xlb, xub)\n\n    def informed_global_search():\n        # Use historical best individuals to guide the search\n        if search_trajectory['individuals'] is not None and len(search_trajectory['individuals']) > 0:\n            historical_best = search_trajectory['individuals'][np.argmin(search_trajectory['rankings'])]\n            mutation_scale = 0.1 * np.exp(-current_gen / max_gen)\n            return np.clip(historical_best + np.random.normal(0, mutation_scale, size=N_P), xlb, xub)\n        else:\n            return np.random.uniform(xlb, xub, size=N_P)\n\n    def decision_based_operator(individual):\n        # Decide between local and global search based on a dynamic threshold\n        threshold = 0.5 * np.sin(np.pi * current_gen / max_gen) + 0.5\n        if np.random.rand() < threshold:\n            return adaptive_local_search(individual, current_gen / max_gen)\n        else:\n            return informed_global_search()\n\n    new_pops = np.array([decision_based_operator(ind) for ind in pops['individuals']])\n    return new_pops",
          "objective": -14.65863,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def differential_mutation(base, a, b, c, f=0.7):\n        new_in = base + f * (a - b + c - base)\n        return np.clip(new_in, xlb, xub)\n\n    new_pops = np.empty_like(pops['individuals'])\n    rankings = pops['rankings']\n    individuals = pops['individuals']\n\n    # Generate a new population using differential evolution\n    for i in range(POP_SIZE):\n        idxs = np.random.choice(POP_SIZE, 4, replace=False)\n        # Ensure indexes are not the individual being mutated\n        base, a, b, c = individuals[idxs]\n        candidate = differential_mutation(base, a, b, c)\n        new_pops[i] = candidate\n    \n    return new_pops",
          "objective": -16.50697,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def differential_evolution_crossover(individuals):\n        \"\"\" Generate offspring using differential evolution strategy. \"\"\"\n        CR = 0.9  # Crossover probability\n        F = 0.8   # Differential weight\n        offspring = np.empty_like(individuals)\n        for i in range(len(individuals)):\n            idxs = np.random.choice(len(individuals), 3, replace=False)\n            x1, x2, x3 = individuals[idxs[0]], individuals[idxs[1]], individuals[idxs[2]]\n            mutant_vector = x1 + F * (x2 - x3)\n            cross_points = np.random.rand(N_P) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, N_P)] = True\n            trial_vector = np.where(cross_points, mutant_vector, individuals[i])\n            offspring[i] = np.clip(trial_vector, xlb, xub)\n        return offspring\n\n    def rank_based_selection(individuals, rankings, num_selected):\n        \"\"\" Select individuals based on rank with a bias towards selecting lower ranks more often. \"\"\"\n        ranks = np.argsort(rankings)\n        weights = 1 / np.arange(1, len(individuals) + 1)\n        probabilities = weights[ranks]\n        probabilities /= probabilities.sum()\n        selected_indices = np.random.choice(len(individuals), num_selected, p=probabilities, replace=False)\n        return individuals[selected_indices]\n\n    elite_size = POP_SIZE // 5  # Keep a fraction of the population as elites\n    elites = pops['individuals'][:elite_size]\n    \n    # Rank based selection for remaining individuals\n    selected_individuals = rank_based_selection(pops['individuals'], pops['rankings'], POP_SIZE - elite_size)\n    \n    # DE crossover to generate new individuals\n    offsprings = differential_evolution_crossover(selected_individuals)\n    \n    # Creating the new population\n    new_pops = np.vstack([elites, offsprings])\n    np.random.shuffle(new_pops)  # Ensure mixing of the new population\n    \n    return new_pops",
          "objective": -16.50998,
          "other_inf": null
     }
]
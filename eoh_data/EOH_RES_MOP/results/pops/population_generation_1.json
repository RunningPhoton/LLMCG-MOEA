[
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def uniform_mutation(individual, lb, ub, mutation_rate):\n        \"\"\"Mutates individual vector elements using a uniform random distribution.\"\"\"\n        mutant = np.copy(individual)\n        for i in range(len(mutant)):\n            if np.random.random() < mutation_rate:\n                mutant[i] = np.random.uniform(lb[i], ub[i])\n        return mutant\n\n    def crossover(parent1, parent2, crossover_rate):\n        \"\"\"Performs uniform crossover between two parents.\"\"\"\n        child = np.copy(parent1)\n        for i in range(len(child)):\n            if np.random.random() < crossover_rate:\n                child[i] = parent2[i]\n        return child\n\n    def select_parents(population):\n        \"\"\"Select parents for crossover using tournament selection.\"\"\"\n        # Tournament size is fixed to 2 for simplicity\n        idx1, idx2 = np.random.randint(0, len(population), 2)\n        if pops['rankings'][idx1] < pops['rankings'][idx2]:\n            parent1 = population[idx1]\n        else:\n            parent1 = population[idx2]\n\n        idx3, idx4 = np.random.randint(0, len(population), 2)\n        if pops['rankings'][idx3] < pops['rankings'][idx4]:\n            parent2 = population[idx3]\n        else:\n            parent2 = population[idx4]\n        \n        return parent1, parent2\n\n    mutation_rate = 0.1 + 0.9 * (current_gen / max_gen)  # Increase mutation rate over time\n    crossover_rate = 0.9 - 0.7 * (current_gen / max_gen)  # Decrease crossover rate over time\n\n    new_pops = np.zeros_like(pops['individuals'])\n\n    # Generate new population\n    for i in range(POP_SIZE):\n        parent1, parent2 = select_parents(pops['individuals'])\n        child = crossover(parent1, parent2, crossover_rate)\n        child = uniform_mutation(child, xlb, xub, mutation_rate)\n        new_pops[i] = child\n\n    return new_pops",
          "objective": -7.52235,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def adaptive_random_crossover(individuals, num_offspring):\n        \"\"\" Generate offspring by a random adaptive crossover mechanism based on current population statistics. \"\"\"\n        offspring = np.empty((num_offspring, N_P))\n        mean_vector = np.mean(individuals, axis=0)\n        std_deviation = np.std(individuals, axis=0)\n        \n        for i in range(num_offspring):\n            idx1, idx2 = np.random.choice(len(individuals), 2, replace=False)\n            crossover_point = np.random.rand(N_P) > 0.5\n            offspring[i] = np.where(crossover_point, individuals[idx1], individuals[idx2])\n            # Introduce some variation based on population distribution\n            offspring[i] += np.random.randn(N_P) * std_deviation * np.exp(-0.1 * current_gen)\n            offspring[i] = np.clip(offspring[i], xlb, xub)\n        return offspring\n\n    def fitness_proportionate_selection(individuals, rankings, num_selected):\n        \"\"\" Select individuals based on their fitness proportionately. \"\"\"\n        min_rank = np.min(rankings)\n        probabilities = 1 / (rankings - min_rank + 1)\n        probabilities /= probabilities.sum()\n        selected_indices = np.random.choice(len(individuals), num_selected, p=probabilities, replace=False)\n        return individuals[selected_indices]\n    \n    elite_size = POP_SIZE // 5  # Keeping a fraction of the population as elites\n    elites = pops['individuals'][:elite_size]\n    \n    # Using Fitness Proportionate Selection for preserving some good but not necessarily elite individuals\n    selected_individuals = fitness_proportionate_selection(pops['individuals'], pops['rankings'], POP_SIZE - elite_size)\n    \n    # Crossover to generate new individuals\n    offsprings = adaptive_random_crossover(selected_individuals, POP_SIZE - elite_size)\n    \n    # Creating new population\n    new_pops = np.vstack([elites, offsprings])\n    np.random.shuffle(new_pops)  # Ensure mixing of the new population\n    \n    return new_pops",
          "objective": -10.50885,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def differential_mutation(base, a, b, c, f=0.7):\n        new_in = base + f * (a - b + c - base)\n        return np.clip(new_in, xlb, xub)\n\n    new_pops = np.empty_like(pops['individuals'])\n    rankings = pops['rankings']\n    individuals = pops['individuals']\n\n    # Generate a new population using differential evolution\n    for i in range(POP_SIZE):\n        idxs = np.random.choice(POP_SIZE, 4, replace=False)\n        # Ensure indexes are not the individual being mutated\n        base, a, b, c = individuals[idxs]\n        candidate = differential_mutation(base, a, b, c)\n        new_pops[i] = candidate\n    \n    return new_pops",
          "objective": -16.50697,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def mutate(individual, mutation_rate=0.1):\n        perturbation_scale = (xub - xlb) * mutation_rate * (1 - (current_gen/max_gen)**2)\n        return individual + np.random.uniform(-perturbation_scale, perturbation_scale, size=individual.shape)\n\n    def crossover(parent1, parent2):\n        alpha = np.random.uniform(0, 1, size=parent1.shape)\n        return alpha * parent1 + (1 - alpha) * parent2\n    \n    def select_parents(population):\n        indices = np.arange(len(population))\n        selected_indices = np.random.choice(indices, 2, replace=False)\n        return population[selected_indices[0]], population[selected_indices[1]]\n\n    def generate_new_individual():\n        if np.random.random() < 0.5:\n            parent1, parent2 = select_parents(pops['individuals'])\n            child = crossover(parent1, parent2)\n        else:\n            elite_individual = pops['individuals'][0]  # Elite selection: take the best one\n            child = mutate(elite_individual)\n        return np.clip(child, xlb, xub)\n\n    new_pops = np.array([generate_new_individual() for _ in range(POP_SIZE)])\n    return new_pops",
          "objective": -19.48152,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    # Backbone idea: Mutation by data-driven searching in neighborhoods and crossover using novel oscillation-based techniques.\n    def community_focus_crossover(individuals, num_offspring, focus_rate=0.05):\n        \"\"\" Generate offspring by oscillating between pairs of top individuals \"\"\"\n        offspring = np.empty((num_offspring, N_P))\n        num_focused = int(num_offspring * focus_rate)\n        focus_indices = np.random.choice(len(individuals), num_focused, replace=False)\n        \n        for i in range(num_offspring):\n            if i < num_focused:\n                idx1 = focus_indices[i % len(focus_indices)]\n                idx2 = focus_indices[(i+1) % len(focus_indices)]\n            else:\n                idx1, idx2 = np.random.choice(len(individuals), 2, replace=False)\n            alpha = 0.5 + 0.5 * np.sin(2 * np.pi * current_gen / max_gen)\n            offspring[i] = alpha * individuals[idx1] + (1 - alpha) * individuals[idx2]\n            offspring[i] = np.clip(offspring[i], xlb, xub)\n        return offspring\n\n    def intelligent_mutation(individuals, num_mutants, search_trajectory, mutation_intensity=0.1):\n        \"\"\" Apply intelligent mutation based on historical search trends \"\"\"\n        mutants = np.copy(individuals[:num_mutants])\n        if search_trajectory['individuals'] is not None:\n            trend = np.mean(search_trajectory['individuals'], axis=0) - np.mean(individuals, axis=0)\n            normalized_trend = trend / (np.linalg.norm(trend) + 1e-6)\n            for i in range(num_mutants):\n                mutation = mutation_intensity * np.random.randn(N_P) * normalized_trend\n                mutants[i] += mutation\n                mutants[i] = np.clip(mutants[i], xlb, xub)\n        return mutants\n\n    num_mutants = int(0.1 * POP_SIZE)\n    num_offspring = POP_SIZE - num_mutants\n    \n    # Perform intelligent mutation and community focus crossover\n    mutated_individuals = intelligent_mutation(pops['individuals'], num_mutants, search_trajectory)\n    offspring = community_focus_crossover(pops['individuals'], num_offspring)\n    \n    # Creating new population\n    new_pops = np.vstack([mutated_individuals, offspring])\n    np.random.shuffle(new_pops)\n    \n    return new_pops",
          "objective": -22.67981,
          "other_inf": null
     },
     {
          "algorithm": "\nMy new algorithm is based on an adaptive blend crossover combined with progressive systematic mutations considering the generation number and the individuals' performance based on their ranking.\n",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def adaptive_blend_crossover(parent1, parent2):\n        beta = 0.5 * np.exp(-0.1 * (max_gen - current_gen))\n        return (1 - beta) * parent1 + beta * parent2\n    \n    def systematic_mutation(individual, rank):\n        factor = 2 * (1 - rank / POP_SIZE)**2 * (current_gen / max_gen)\n        mutation_strength = 0.2 * np.exp(-2 * current_gen / max_gen) * np.cos(2 * np.pi * current_gen / max_gen)\n        mutation_vector = mutation_strength * np.random.normal(0, 1, N_P) * (xub - xlb)\n        return np.clip(individual + factor * mutation_vector, xlb, xub)\n    \n    new_pops = np.zeros_like(pops['individuals'])\n    \n    # Elite retention strategy\n    elite_size = max(1, POP_SIZE // 10)\n    new_pops[:elite_size] = pops['individuals'][:elite_size]\n    \n    # Generate new individuals\n    for i in range(elite_size, POP_SIZE):\n        if np.random.rand() < 0.8:\n            # Perform crossover mostly\n            idx1, idx2 = np.random.choice(elite_size, 2, replace=False)\n            new_pops[i] = adaptive_blend_crossover(pops['individuals'][idx1], pops['individuals'][idx2])\n        else:\n            # Mutation based on ranking\n            idx = np.random.randint(0, POP_SIZE)\n            individual_rank = np.where(np.argsort(pops['rankings']) == idx)[0][0]\n            new_pops[i] = systematic_mutation(pops['individuals'][idx], individual_rank)\n    \n    return new_pops",
          "objective": -23.74573,
          "other_inf": null
     },
     {
          "algorithm": "\nMy novel algorithm integrates population partitioning for selective breeding and a dynamic adaptive mutation based on historical performance data, aiming for robust exploration and exploitation throughout generations.\n",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def adaptive_mutation(individual, exploration_factor):\n        mutation_scale = exploration_factor * (xub - xlb)\n        mutation = np.random.normal(0, mutation_scale, N_P)\n        return np.clip(individual + mutation, xlb, xub)\n    \n    def selective_breeding(parents, num_offspring):\n        offspring = np.empty((num_offspring, N_P))\n        for i in range(num_offspring):\n            p1, p2 = np.random.choice(len(parents), 2, replace=False)\n            cross_point = np.random.randint(1, N_P)\n            offspring[i, :cross_point] = parents[p1, :cross_point]\n            offspring[i, cross_point:] = parents[p2, cross_point:]\n        return offspring\n    \n    # Dynamic exploration factor adjusts mutation strength over generations and population performance\n    mean_rank = np.mean(pops['rankings'])\n    exploration_factor = np.exp(-(current_gen / max_gen) * mean_rank)\n    \n    # Partitioning population into top performers and others\n    top_performers_ratio = 0.5 - 0.4 * (current_gen / max_gen)\n    num_top_performers = int(POP_SIZE * top_performers_ratio)\n    top_performers = pops['individuals'][:num_top_performers]\n    remaining_performers = pops['individuals'][num_top_performers:]\n    \n    # Offspring generation through selective breeding amongst top performers\n    num_offspring = POP_SIZE - num_top_performers\n    offspring = selective_breeding(top_performers, num_offspring)\n    \n    # Mutate the remaining performers\n    mutated_performers = np.array([adaptive_mutation(ind, exploration_factor) for ind in remaining_performers])\n    \n    # Combining new generation\n    new_pops = np.vstack([top_performers, offspring, mutated_performers])\n    np.random.shuffle(new_pops)  # Ensuring randomness in the new population\n\n    return new_pops",
          "objective": -24.28075,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    # Define sub-function for directional mutation inspired by gradient methods\n    def directional_mutate(individual, direction_scale=0.5):\n        # Create a mutation direction vector\n        direction = np.random.normal(0, 1, size=individual.shape)\n        # Normalize the mutation direction\n        direction /= np.linalg.norm(direction)\n        # Compute mutation magnitude, which decreases over generations\n        magnitude = (xub - xlb) * direction_scale * np.exp(-current_gen/max_gen)\n        return individual + direction * magnitude\n\n    # Define sub-function for uniform crossover\n    def uniform_crossover(parent1, parent2):\n        # Generate a binary mask\n        mask = np.random.randint(2, size=parent1.shape)\n        # Crossover using mask\n        offspring = np.where(mask == 1, parent1, parent2)\n        return offspring\n    \n    # Define sub-function to enhance diversity using search history\n    def diversity_inspired_crossover():\n        if search_trajectory['individuals'] is not None and len(search_trajectory['individuals']) > 0:\n            history_sample = search_trajectory['individuals'][np.random.randint(len(search_trajectory['individuals']))]\n        else:\n            history_sample = pops['individuals'][np.random.randint(len(pops['individuals']))]\n        parent = pops['individuals'][np.random.randint(len(pops['individuals']))]\n        return uniform_crossover(parent, history_sample)\n\n    # Generate new population\n    new_pops = np.zeros((POP_SIZE, N_P))\n    for i in range(POP_SIZE):\n        if np.random.random() < 0.5:\n            # Apply diversity inspired crossover 50% of the time\n            new_pops[i] = diversity_inspired_crossover()\n        else:\n            # Apply directional mutation otherwise\n            new_pops[i] = directional_mutate(pops['individuals'][np.random.randint(POP_SIZE)])\n        # Ensure boundaries are respected\n        new_pops[i] = np.clip(new_pops[i], xlb, xub)\n\n    return new_pops",
          "objective": -26.2354,
          "other_inf": null
     },
     {
          "algorithm": "A novel reproduction function that utilizes adaptive mutation based on historical search trajectories and differential evolution strategies to generate the next population.",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def adaptive_mutation(individual, gen):\n        mutation_rate = 0.1 + (0.9 * gen / max_gen)  # Increase mutation rate over generations\n        mutation_vector = np.random.uniform(-1, 1, size=N_P) * (xub - xlb) * mutation_rate\n        new_individual = individual + mutation_vector\n        new_individual = np.clip(new_individual, xlb, xub)  # Ensure bounds are respected\n        return new_individual\n\n    def differential_evolution(individuals):\n        new_population = np.empty_like(individuals)\n        for i in range(len(individuals)):\n            idxs = [idx for idx in range(len(individuals)) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = individuals[a] + 0.8 * (individuals[b] - individuals[c])\n            mutant = np.clip(mutant, xlb, xub)\n            cross_points = np.random.rand(N_P) < 0.7\n            trial = np.where(cross_points, mutant, individuals[i])\n            new_population[i] = trial\n        return new_population\n\n    if current_gen < max_gen // 2:\n        # Use adaptive mutation in the first half of the generations\n        new_pops = np.array([adaptive_mutation(ind, current_gen) for ind in pops['individuals']])\n    else:\n        # Use differential evolution in the second half of the generations\n        new_pops = differential_evolution(pops['individuals'])\n\n    return new_pops",
          "objective": -26.75627,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def wave_mutation(individual):\n        frequency = (max_gen - current_gen) / max_gen  # Higher frequency when approaching the end\n        amplitude = 0.2 / (current_gen + 1)  # Amplitude decreases with each generation\n        phase = np.pi * frequency\n        mutation_vector = amplitude * np.sin(2 * np.pi * frequency * np.arange(N_P) + phase)\n        new_individual = individual + mutation_vector * (xub - xlb)\n        return np.clip(new_individual, xlb, xub)\n\n    def guided_crossover(parent1, parent2):\n        alpha = 0.5 * (1 + np.cos(np.pi * current_gen / max_gen))  # Guidance parameter changing sinusoidally\n        child = alpha * parent1 + (1 - alpha) * parent2\n        return np.clip(child, xlb, xub)\n\n    # Determine elite size and select elites (top performing individuals)\n    elite_size = POP_SIZE // 5\n    elites = pops['individuals'][:elite_size]\n\n    # Generate new population - Wave mutation for variance, guided crossover for combination\n    new_pops = np.empty_like(pops['individuals'])\n    new_pops[:elite_size] = elites  # Preserve elites\n\n    for i in range(elite_size, POP_SIZE):\n        if np.random.rand() > 0.5:  # Random choice to emphasize diversity\n            parent1_index = np.random.randint(0, elite_size)\n            parent2_index = np.random.randint(0, POP_SIZE)\n            new_pops[i] = guided_crossover(pops['individuals'][parent1_index], pops['individuals'][parent2_index])\n        else:\n            individual_index = np.random.randint(0, POP_SIZE)\n            new_pops[i] = wave_mutation(pops['individuals'][individual_index])\n            \n    return new_pops",
          "objective": -26.95424,
          "other_inf": null
     }
]
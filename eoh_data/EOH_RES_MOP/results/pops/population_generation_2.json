[
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    # Adaptive mutation that factors in generational distance\n    def focused_mutate(individual, top_performer, mutation_scale=0.3):\n        # Weight more towards top performers as generations go by\n        beta = np.random.normal(0, 1, size=individual.shape)\n        weight = np.exp(-current_gen / max_gen)\n        mutation_vector = mutation_scale * (top_performer - individual) * weight + beta * (1 - weight)\n        return individual + mutation_vector\n\n    # Biased crossover giving preference to better-ranked individuals\n    def biased_crossover(parent1, parent2, rank1, rank2):\n        # Higher chance to pick characteristics from better-ranked parent\n        p = rank1 / (rank1 + rank2) if rank1 + rank2 != 0 else 0.5\n        crossover_mask = np.random.rand(N_P) < p\n        offspring = np.where(crossover_mask, parent1, parent2)\n        return offspring\n\n    # Initialize new population array\n    new_pops = np.zeros((POP_SIZE, N_P))\n\n    # Ensure there are previous individuals to sample from\n    history_available = search_trajectory['individuals'] is not None and len(search_trajectory['individuals']) > 0\n\n    for i in range(POP_SIZE):\n        idx1, idx2 = np.random.randint(0, POP_SIZE, size=2)\n        parent1 = pops['individuals'][idx1]\n        parent2 = pops['individuals'][idx2]\n        rank1 = pops['rankings'][idx1]\n        rank2 = pops['rankings'][idx2]\n\n        if np.random.rand() < 0.5:\n            # Perform biased crossover\n            new_pops[i] = biased_crossover(parent1, parent2, rank1, rank2)\n        else:\n            # Perform focused mutation based on the best available individual or a historical point\n            if history_available and np.random.rand() < 0.5:\n                history_idx = np.random.choice(len(search_trajectory['individuals']))\n                ref_individual = search_trajectory['individuals'][history_idx]\n            else:\n                ref_individual = pops['individuals'][np.argmin(pops['rankings'])]\n\n            new_pops[i] = focused_mutate(parent1, ref_individual)\n\n        # Clip to stay within bounds\n        new_pops[i] = np.clip(new_pops[i], xlb, xub)\n\n    return new_pops",
          "objective": -5.63161,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def uniform_mutation(individual, lb, ub, mutation_rate):\n        \"\"\"Mutates individual vector elements using a uniform random distribution.\"\"\"\n        mutant = np.copy(individual)\n        for i in range(len(mutant)):\n            if np.random.random() < mutation_rate:\n                mutant[i] = np.random.uniform(lb[i], ub[i])\n        return mutant\n\n    def crossover(parent1, parent2, crossover_rate):\n        \"\"\"Performs uniform crossover between two parents.\"\"\"\n        child = np.copy(parent1)\n        for i in range(len(child)):\n            if np.random.random() < crossover_rate:\n                child[i] = parent2[i]\n        return child\n\n    def select_parents(population):\n        \"\"\"Select parents for crossover using tournament selection.\"\"\"\n        # Tournament size is fixed to 2 for simplicity\n        idx1, idx2 = np.random.randint(0, len(population), 2)\n        if pops['rankings'][idx1] < pops['rankings'][idx2]:\n            parent1 = population[idx1]\n        else:\n            parent1 = population[idx2]\n\n        idx3, idx4 = np.random.randint(0, len(population), 2)\n        if pops['rankings'][idx3] < pops['rankings'][idx4]:\n            parent2 = population[idx3]\n        else:\n            parent2 = population[idx4]\n        \n        return parent1, parent2\n\n    mutation_rate = 0.1 + 0.9 * (current_gen / max_gen)  # Increase mutation rate over time\n    crossover_rate = 0.9 - 0.7 * (current_gen / max_gen)  # Decrease crossover rate over time\n\n    new_pops = np.zeros_like(pops['individuals'])\n\n    # Generate new population\n    for i in range(POP_SIZE):\n        parent1, parent2 = select_parents(pops['individuals'])\n        child = crossover(parent1, parent2, crossover_rate)\n        child = uniform_mutation(child, xlb, xub, mutation_rate)\n        new_pops[i] = child\n\n    return new_pops",
          "objective": -7.52235,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def adaptive_random_crossover(individuals, num_offspring):\n        \"\"\" Generate offspring by a random adaptive crossover mechanism based on current population statistics. \"\"\"\n        offspring = np.empty((num_offspring, N_P))\n        mean_vector = np.mean(individuals, axis=0)\n        std_deviation = np.std(individuals, axis=0)\n        \n        for i in range(num_offspring):\n            idx1, idx2 = np.random.choice(len(individuals), 2, replace=False)\n            crossover_point = np.random.rand(N_P) > 0.5\n            offspring[i] = np.where(crossover_point, individuals[idx1], individuals[idx2])\n            # Introduce some variation based on population distribution\n            offspring[i] += np.random.randn(N_P) * std_deviation * np.exp(-0.1 * current_gen)\n            offspring[i] = np.clip(offspring[i], xlb, xub)\n        return offspring\n\n    def fitness_proportionate_selection(individuals, rankings, num_selected):\n        \"\"\" Select individuals based on their fitness proportionately. \"\"\"\n        min_rank = np.min(rankings)\n        probabilities = 1 / (rankings - min_rank + 1)\n        probabilities /= probabilities.sum()\n        selected_indices = np.random.choice(len(individuals), num_selected, p=probabilities, replace=False)\n        return individuals[selected_indices]\n    \n    elite_size = POP_SIZE // 5  # Keeping a fraction of the population as elites\n    elites = pops['individuals'][:elite_size]\n    \n    # Using Fitness Proportionate Selection for preserving some good but not necessarily elite individuals\n    selected_individuals = fitness_proportionate_selection(pops['individuals'], pops['rankings'], POP_SIZE - elite_size)\n    \n    # Crossover to generate new individuals\n    offsprings = adaptive_random_crossover(selected_individuals, POP_SIZE - elite_size)\n    \n    # Creating new population\n    new_pops = np.vstack([elites, offsprings])\n    np.random.shuffle(new_pops)  # Ensure mixing of the new population\n    \n    return new_pops",
          "objective": -10.50885,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def balanced_search(individual, phase):\n        # Linearly decrease local exploration and increase global exploitation\n        local_ratio = 1 - phase\n        global_ratio = phase\n        step_local = 0.05 * np.sqrt(1 - phase)\n        step_global = 0.2 + 0.1 * np.sin(np.pi * current_gen / max_gen)\n\n        local_pert = np.random.normal(0, step_local, size=N_P)\n        global_pert = np.random.normal(0, step_global, size=N_P)\n        \n        new_individual = individual + local_ratio * local_pert + global_ratio * global_pert\n        return np.clip(new_individual, xlb, xub)\n\n    def crossover(individual1, individual2):\n        # Single-point crossover\n        point = np.random.randint(N_P)\n        offspring = np.concatenate([individual1[:point], individual2[point:]])\n        return offspring\n\n    def evolve_population():\n        new_population = []\n        for i in range(POP_SIZE):\n            if np.random.rand() < 0.5:  # Choose whether to mutate or crossover\n                selected = crossover(pops['individuals'][i], pops['individuals'][np.random.randint(POP_SIZE)])\n            else:\n                selected = balanced_search(pops['individuals'][i], current_gen / max_gen)\n            new_population.append(selected)\n        return np.array(new_population)\n\n    new_pops = evolve_population()\n    return new_pops",
          "objective": -14.64913,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def adaptive_local_search(individual, gen_progress):\n        # Adjust the step size based on the generation progress\n        step_size = 0.1 * (1 - gen_progress) ** 2\n        perturbations = np.random.normal(0, step_size, size=N_P)\n        return np.clip(individual + perturbations, xlb, xub)\n\n    def informed_global_search():\n        # Use historical best individuals to guide the search\n        if search_trajectory['individuals'] is not None and len(search_trajectory['individuals']) > 0:\n            historical_best = search_trajectory['individuals'][np.argmin(search_trajectory['rankings'])]\n            mutation_scale = 0.1 * np.exp(-current_gen / max_gen)\n            return np.clip(historical_best + np.random.normal(0, mutation_scale, size=N_P), xlb, xub)\n        else:\n            return np.random.uniform(xlb, xub, size=N_P)\n\n    def decision_based_operator(individual):\n        # Decide between local and global search based on a dynamic threshold\n        threshold = 0.5 * np.sin(np.pi * current_gen / max_gen) + 0.5\n        if np.random.rand() < threshold:\n            return adaptive_local_search(individual, current_gen / max_gen)\n        else:\n            return informed_global_search()\n\n    new_pops = np.array([decision_based_operator(ind) for ind in pops['individuals']])\n    return new_pops",
          "objective": -14.65863,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def differential_mutation(base, a, b, c, f=0.7):\n        new_in = base + f * (a - b + c - base)\n        return np.clip(new_in, xlb, xub)\n\n    new_pops = np.empty_like(pops['individuals'])\n    rankings = pops['rankings']\n    individuals = pops['individuals']\n\n    # Generate a new population using differential evolution\n    for i in range(POP_SIZE):\n        idxs = np.random.choice(POP_SIZE, 4, replace=False)\n        # Ensure indexes are not the individual being mutated\n        base, a, b, c = individuals[idxs]\n        candidate = differential_mutation(base, a, b, c)\n        new_pops[i] = candidate\n    \n    return new_pops",
          "objective": -16.50697,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def cooperative_crossover(parent1, parent2):\n        # Create offspring by taking the mean of both parents\n        return (parent1 + parent2) / 2\n\n    def adaptive_mutation(individual, mutation_scale=0.2):\n        # Mutation depends on the stage of generation\n        mutation_intensity = mutation_scale * (1 - (current_gen / max_gen))\n        mutation_vector = np.random.normal(0, mutation_intensity, size=individual.shape)\n        return individual + mutation_vector\n\n    new_pops = np.zeros((POP_SIZE, N_P))\n\n    best_idx = np.argmin(pops['rankings'])\n    best_individual = pops['individuals'][best_idx]\n\n    for i in range(POP_SIZE):\n        idx1, idx2 = np.random.randint(0, POP_SIZE, size=2)\n        parent1 = pops['individuals'][idx1]\n        parent2 = pops['individuals'][idx2]\n\n        if np.random.rand() < 0.7:\n            # Perform cooperative crossover\n            new_pops[i] = cooperative_crossover(parent1, parent2)\n        else:\n            # Perform adaptive mutation\n            new_pops[i] = adaptive_mutation(parent1)\n\n        # Clip to stay within bounds\n        new_pops[i] = np.clip(new_pops[i], xlb, xub)\n\n    return new_pops",
          "objective": -17.8101,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def adaptive_local_search(individual, step_size, rank):\n        mod_step_size = step_size * (1 - (rank / POP_SIZE))  # Smaller step for better individuals\n        perturbations = np.random.uniform(-mod_step_size, mod_step_size, size=N_P)\n        new_individual = individual + perturbations\n        return np.clip(new_individual, xlb, xub)\n\n    def informed_global_search():\n        if search_trajectory['individuals'] is not None and len(search_trajectory['individuals']) > 0:\n            selected_idx = np.random.randint(0, len(search_trajectory['individuals']))\n            return search_trajectory['individuals'][selected_idx]  # Use a past individual\n        else:\n            return np.random.uniform(xlb, xub, size=N_P)\n    \n    def elite_preservation_operator(individual, rank):\n        # Mix between all methods considering generation and ranking\n        if np.random.rand() < 0.5:\n            return adaptive_local_search(individual, 0.1 * (1 - current_gen / max_gen), rank)\n        elif np.random.rand() < 0.2:\n            return individual  # Preserve top elites directly sometimes\n        else:\n            return informed_global_search()\n\n    new_pops = np.array([elite_preservation_operator(pops['individuals'][i], pops['rankings'][i]) for i in range(POP_SIZE)])\n\n    return new_pops",
          "objective": -19.05378,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n    \n    def mutate(individual, mutation_rate=0.1):\n        perturbation_scale = (xub - xlb) * mutation_rate * (1 - (current_gen/max_gen)**2)\n        return individual + np.random.uniform(-perturbation_scale, perturbation_scale, size=individual.shape)\n\n    def crossover(parent1, parent2):\n        alpha = np.random.uniform(0, 1, size=parent1.shape)\n        return alpha * parent1 + (1 - alpha) * parent2\n    \n    def select_parents(population):\n        indices = np.arange(len(population))\n        selected_indices = np.random.choice(indices, 2, replace=False)\n        return population[selected_indices[0]], population[selected_indices[1]]\n\n    def generate_new_individual():\n        if np.random.random() < 0.5:\n            parent1, parent2 = select_parents(pops['individuals'])\n            child = crossover(parent1, parent2)\n        else:\n            elite_individual = pops['individuals'][0]  # Elite selection: take the best one\n            child = mutate(elite_individual)\n        return np.clip(child, xlb, xub)\n\n    new_pops = np.array([generate_new_individual() for _ in range(POP_SIZE)])\n    return new_pops",
          "objective": -19.48152,
          "other_inf": null
     },
     {
          "algorithm": "```",
          "code": "def next_generation(pops, search_trajectory, xlb, xub, POP_SIZE, N_P, current_gen, max_gen):\n    import numpy as np\n\n    def local_search(individual, step_size):\n        # Perform a local search by perturbing each dimension of the individual\n        perturbations = np.random.uniform(-step_size, step_size, size=N_P)\n        new_individual = individual + perturbations\n        return np.clip(new_individual, xlb, xub)\n\n    def global_search():\n        # Generate a completely new individual within the bounds\n        return np.random.uniform(xlb, xub, size=N_P)\n\n    def hybrid_operator(individual):\n        # Combine local and global search based on the phase of the generation\n        if np.random.rand() < 0.5:\n            return local_search(individual, 0.1 * (1 - current_gen / max_gen))\n        else:\n            return global_search()\n\n    new_pops = np.array([hybrid_operator(ind) for ind in pops['individuals']])\n    return new_pops",
          "objective": -19.98502,
          "other_inf": null
     }
]